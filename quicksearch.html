<html>
<head>
</head>
<body style="background: transparent;">
    <script src="scripts/docstrap.lib.js"></script>
    <script src="scripts/lunr.min.js"></script>
    <script src="scripts/fulltext-search.js"></script>

    <script type="text/x-docstrap-searchdb">
    {"audit.js.html":{"id":"audit.js.html","title":"Source: audit.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: audit.js 'use strict'; const { Writable: WritableStream } = require('stream'); const assert = require('assert'); const crypto = require('crypto'); const constants = require('./constants'); const MerkleTree = require('mtree'); const utils = require('./utils'); /** * Represents a streaming audit challenge generator */ class Audit extends WritableStream { /** * @constructor * @param {number} audits - Total number of challenges to generate */ constructor(audits) { super(); assert(typeof audits === 'number', 'Invalid number of audits supplied'); assert(!Number.isNaN(audits), 'Invalid number of audits supplied'); assert(Number.isFinite(audits), 'Invalid number of audits supplied'); this._audits = audits; this._finished = false; this._challenges = []; this._inputs = this._prepareChallenges(); this.on('finish', this._generateTree.bind(this)); } /** * Returns the bottom leaves of the merkle tree for sending to farmer * @returns {Array} leaves - Bottom merkle leaves of audit tree */ getPublicRecord() { assert(this._finished, 'Challenge generation is not finished'); return this._tree.level(this._tree.levels() - 1) .map((i) =&gt; i.toString('hex')); } /** * Returns the challenges, the tree depth, and merkle root * @returns {Object} challenge - Private audit record with challenges */ getPrivateRecord() { assert(this._finished, 'Challenge generation is not finished'); return { root: this._tree.root(), depth: this._tree.levels(), challenges: this._challenges.map((i) =&gt; i.toString('hex')) }; } /** * Implements the underlying write method * @private */ _write(bytes, encoding, next) { this._inputs.forEach((input, i) =&gt; { if (i &lt; this._audits) { input.update(bytes); } }); next(); } /** * Prepares the challenge hasher instances * @private */ _prepareChallenges() { let iterations = 0; let inputs = []; while (iterations &lt; this._audits) { const challenge = this._generateChallenge(); const input = this._createResponseInput(challenge); this._challenges.push(challenge); inputs.push(input); iterations++; } while (iterations &lt; utils.getNextPowerOfTwo(this._audits)) { inputs.push(utils.rmd160sha256('')); iterations++; } return inputs; } /** * Generate the audit merkle tree from a series of challenges * @private */ _generateTree() { this._finished = true; this._tree = new MerkleTree(this._inputs.map((input, i) =&gt; { if (i &gt;= this._audits) { return input; } else { return utils.rmd160sha256(utils.rmd160(input.digest())); } }), utils.rmd160sha256); } /** * Generate a random challenge buffer * @private * @returns {buffer} */ _generateChallenge() { return crypto.randomBytes(constants.AUDIT_BYTES); } /** * Create a challenge response input to merkle tree * @private */ _createResponseInput(challenge) { return crypto.createHash('sha256').update(challenge); } /** * Returns a new instance from the predefined challenges and tree * @param {array} challenges - The precomputed challenges * @param {array} tree - The bottom leaves of the existing merkle tree * @returns {Audit} */ static fromRecords(challenges, tree) { assert(Array.isArray(challenges), 'Invalid challenges supplied'); assert(Array.isArray(tree), 'Invalid tree supplied'); assert( tree.length === utils.getNextPowerOfTwo(challenges.length), 'Challenges and tree do not match' ); tree = tree.map((i) =&gt; Buffer.from(i, 'hex')); const auditor = new Audit(challenges.length); auditor._challenges = challenges; auditor._tree = new MerkleTree(tree, utils.rmd160sha256); auditor._finished = true; return auditor; } } module.exports = Audit; × Search results Close "},"bridge.js.html":{"id":"bridge.js.html","title":"Source: bridge.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: bridge.js 'use strict'; const constants = require('./constants'); const { EventEmitter } = require('events'); const BusBoy = require('busboy'); const ReedSolomon = require('@ronomon/reed-solomon'); const http = require('http'); const ws = require('ws'); const utils = require('./utils'); const fs = require('fs'); const merge = require('merge'); const express = require('express'); const auth = require('basic-auth'); const crypto = require('crypto'); const { tmpdir } = require('os'); const path = require('path'); const mkdirp = require('mkdirp'); const uuid = require('uuid'); const AuditStream = require('./audit'); const Proof = require('./proof'); const { knuthShuffle } = require('knuth-shuffle'); const stream = require('stream'); const async = require('async'); const ms = require('ms'); const rimraf = require('rimraf'); const { slice } = require('stream-slice'); const BUFFER = require('buffer'); const bytes = require('bytes'); const cors = require('cors'); const url = require('url'); const { utils: keyutils } = require('kad-spartacus'); const concat = require('concat-stream'); const qs = require('querystring'); const jsonrpc = require('jsonrpc-lite'); /** * Represents a local HTTP(s) server that abstracts the upload and download * of files away to a simple request. Files are encrypted to the given public * key, split into shards for erasure codes. Prepped for distribution and * queued for storing in the network. Bridge exposes a simple API for getting * status of transfers and previously stored objects. * * GET / (List objects as JSON - or serve Web GUI) * GET /{hash} (Download object) * DELETE /{hash} (Delete object) * POST / (Upload object - Multipart) * * If auth is enabled, then the websocket event stream expects: * ?auth={base64(user:pass)} as the query string */ class Bridge extends EventEmitter { static get DEFAULTS() { return { auth: { user: null, pass: null }, tempStagingDirectory: path.join( tmpdir(), `staging.${crypto.randomBytes(16).toString('hex')}` ), providerFailureBlacklistTimeout: ms('6HR'), providerCapacityPoolTimeout: ms('24HR') }; } /** * @constructor * @param {Node} node * @param {object} options */ constructor(node, options) { super(); this.options = merge(Bridge.DEFAULTS, options); this.api = express(); this.node = node; this.database = this.node.database; this.server = this._createServer(this.api); this.wss = new ws.Server({ server: this.server, verifyClient: (info, cb) =&gt; this._verifyClient(info, cb) }); /* istanbul ignore else */ if (!fs.existsSync(this.options.tempStagingDirectory)) { mkdirp.sync(this.options.tempStagingDirectory); } this.server.setTimeout(0); this._bindRoutes(); this._addLoggerStream(); setInterval(() =&gt; this.audit(), constants.AUDIT_INTERVAL); } /** * @private */ _createServer(handler) { return http.createServer(handler); } /** * @private */ _verifyClient(info, callback) { const { user, pass } = this.options.auth; if (user &amp;&amp; pass) { const creds = auth(info.req); if (!creds || !(creds.name === user &amp;&amp; creds.pass === pass)) { return callback(false, 401, 'Not authorized'); } } callback(true); } /** * Listens on the given port and hostname * @param {number} port * @param {string} hostname * @param {function} callback */ listen() { this.server.listen(...arguments); this.wss.on('connection', () =&gt; { this.notifyClients('CONNECT_INFO', null, 'Connected', { clients: this.wss.clients.size }); }); } /** * Sends a state update payload to all connected clients via the websocket */ notifyClients(type, reference, message, data) { this.wss.clients.forEach(client =&gt; { if (client.readyState === ws.OPEN) { client.send(JSON.stringify( jsonrpc.notification(type, [reference, message, data]) )); } }); } /** * @private */ _addLoggerStream() { this.node.logger.addStream({ stream: new stream.Writable({ write: (data, encoding, callback) =&gt; { this.notifyClients('LOG_RAW', null, '', JSON.parse(data.toString())); callback(); } }) }); } /** * Creates request router and handler stack * @private * @returns {function} */ _bindRoutes() { // NB: Used for all routes this.api.use(cors()); this.api.use(this.authenticate.bind(this)); // NB: Generate stats endpoint this.api.get('/', this.getNodeStatus.bind(this)); // NB: Used for peer profiles this.api.get('/providers', this.listProfiles.bind(this)); this.api.get('/providers/:identity', this.getProfile.bind(this)); this.api.get('/providers/:id/score', this.getReputationImpact.bind(this)); // NB: Used for manipulating objects this.api.get('/objects', this.listObjects.bind(this)); this.api.get('/objects/:id', this.downloadObject.bind(this)); this.api.put('/objects/:id', this.retryUploadObject.bind(this)); this.api.get('/objects/:id/info', this.getObjectInfo.bind(this)); this.api.get('/objects/:id/magnet', this.getObjectMagnet.bind(this)); this.api.post('/objects', this.uploadObject.bind(this)); this.api.put('/objects', this.resolveObject.bind(this)); this.api.delete('/objects/:id', this.destroyObject.bind(this)); // NB: Fallthrough to error handler this.api.use(this.error.bind(this)); } /** * Handles request authentication if defined * @param {object} request * @param {object} response * @param {function} next */ authenticate(req, res, next) { const { user, pass } = this.options.auth; const error = new Error('Not authorized'); error.code = 401; if (user &amp;&amp; pass) { const creds = auth(req); if (!creds || !(creds.name === user &amp;&amp; creds.pass === pass)) { res.setHeader('WWW-Authenticate', 'Basic realm=&quot;ORC&quot;'); return next(error); } } next(); } /** * Responds to requests with error code and message * @param {error} error * @param {object} request * @param {object} response * @param {function} next */ error(err, req, res, next) { if (!err) { return next(); } res.writeHead(err.code || 500); res.write(err.message); res.end(); } /** * Returns status information about the running node * @param {object} request * @param {object} response * @param {function} next */ getNodeStatus(req, res, next) { this.node.shards.size((err, providing) =&gt; { if (err) { return next(err) } let peers = []; this.node.router.forEach(bucket =&gt; { for (let contact of bucket) { peers.push(contact); } }); res.json({ identity: this.node.identity.toString('hex'), contact: this.node.contact, peers, providing, versions: require('./version') }); }); } /** * Scans the object database and returns all index entries * @param {object} request * @param {object} response * @param {function} next */ listObjects(req, res) { this.database.ObjectPointer.find({}, (err, pointers) =&gt; { /* istanbul ignore if */ if (err) { res.status(500).send(err.message); } else { res.status(200).send(pointers.map(o =&gt; o.toObject())); } }); } /** * Gets object information by unique ID * @param {object} request * @param {object} response * @param {function} next */ getObjectInfo(req, res, next) { this.database.ObjectPointer.findOne({ _id: req.params.id }, (err, obj) =&gt; { if (err) { return next(err); } if (!obj) { return next(new Error('Not found')); } res.status(200).send(obj.toObject()); }); } /** * Retries the object upload * @param {object} request * @param {object} response * @param {function} next */ retryUploadObject(req, res, next) { this.database.ObjectPointer.findOne({ _id: req.params.id }, (err, obj) =&gt; { /* istanbul ignore if */ if (err) { return next(err); } if (obj.status === 'finished') { return next(new Error('Object is not queued')); } const ciphertext = path.join(this.options.tempStagingDirectory, obj.hash, 'ciphertext'); this.distribute(ciphertext, obj, (err, object) =&gt; { if (err) { return next(err); } res.status(201).send(object.toObject()); }); }); } /** * Queues the object for upload to the network * @param {object} request * @param {object} response * @param {function} next */ uploadObject(req, res, next) { const busboy = new BusBoy({ headers: req.headers }); const objects = []; const policies = []; const id = uuid.v4(); busboy.on('field', (name, value) =&gt; { if (name === 'policy') { policies.push(value); } }); /* eslint max-params: [2, 5] */ busboy.once('file', (field, file, name, encoding, mime) =&gt; { let tmp = path.join(this.options.tempStagingDirectory, id); let size = 0; try { mkdirp.sync(tmp); } catch (err) { /* istanbul ignore next */ return next(new Error('Failed to write to staging area, ' + 'does ORC have permission?')); } const hash = crypto.createHash('sha256'); const hasher = new stream.Transform({ transform: (data, enc, cb) =&gt; { size += data.length; hash.update(data); cb(null, data); } }); const { publicKey: ecpub, privateKey: ecprv } = keyutils.toHDKeyFromSeed(); const writer = fs.createWriteStream(path.join(tmp, 'ciphertext')); const cipher = utils.createCipher(ecpub, ecprv); objects.push({ name, encoding, mimetype: mime }); file.pipe(hasher).pipe(cipher).pipe(writer).on('finish', () =&gt; { const digest = hash.digest('hex'); try { let target = path.join(path.dirname(tmp), digest); if (!fs.existsSync(target)) { fs.mkdirSync(target); } fs.renameSync( path.join(tmp, 'ciphertext'), path.join(target, 'ciphertext') ); rimraf.sync(tmp); tmp = target; } catch (err) { /* istanbul ignore next */ return next(err); } const ciphertext = path.join(tmp, 'ciphertext'); const object = new this.database.ObjectPointer({ name, encoding, size, policies, ecpub: ecpub.toString('hex'), ecprv: ecprv.toString('hex'), mimetype: mime, hash: digest, shards: [], status: 'queued' }); /* istanbul ignore if */ if (size &gt; BUFFER.kMaxLength) { fs.unlink(path.join(tmp, 'ciphertext'), () =&gt; { return next(new Error( `File size exceeds max supported (${bytes(BUFFER.kMaxLength)})` )); }); } object.save(() =&gt; { this.distribute(ciphertext, object, (err, object) =&gt; { if (err) { return next(err); } res.status(201).send(object.toObject()); }); }); }); }); req.pipe(busboy); } /** * Takes the supplied file path and applies erasure codes, then attempts to * distribute the shards across the network * @param {string} filepath - Path to the file to distribute * @param {object} metadata * @param {ObjectPointer} object * @param {function} callback * @returns {EventEmitter} */ distribute(filepath, object, callback) { const stat = fs.statSync(filepath); const rsparams = utils.getErasureParameters(stat.size); const rs = new ReedSolomon(rsparams.shards, rsparams.parity); const encodeErasure = (callback) =&gt; { fs.readFile(filepath, (err, file) =&gt; { /* istanbul ignore if */ if (err) { return callback(err); } let parity = []; let { size } = rsparams; for (let i = 0; i &lt; rsparams.parity; i++) { parity.push(Buffer.alloc(rsparams.size)); } file = Buffer.concat([file, Buffer.concat(parity)]); rs.encode(file, 0, file.length, size, 0, size, (err) =&gt; { /* istanbul ignore if */ if (err) { callback(err); } else { callback(null, file, rsparams, object); } }); }); } const prepareShards = (file, rsparams, object, callback) =&gt; { let shards = []; let position = 0; const prepareContracts = () =&gt; { async.eachSeries(shards, (shard, next) =&gt; { const audit = new AuditStream(constants.NUM_CHALLENGES); const readStream = fs.createReadStream(shard.path); const hash = crypto.createHash('sha256'); const hasher = new stream.Transform({ transform: (data, enc, cb) =&gt; { hash.update(data); cb(null, data); } }); readStream.pipe(hasher).pipe(audit).on('finish', () =&gt; { const record = audit.getPrivateRecord(); shard.audits = {}; shard.audits.root = record.root.toString('hex') shard.audits.depth = record.depth; shard.audits.challenges = record.challenges; shard.proposal = new this.database.ShardContract({ shardHash: utils.rmd160(hash.digest()).toString('hex'), shardSize: rsparams.size, auditLeaves: audit.getPublicRecord(), ownerParentKey: this.node.contact.xpub, ownerIndex: this.node.contact.index, ownerIdentity: this.node.identity.toString('hex'), accessPolicies: object.policies }); shard.proposal.sign('owner', this.node.spartacus.privateKey); next(); }); }, () =&gt; { object.shards = shards; object.save(() =&gt; callback(null, shards, object)); }); } async.timesLimit(rsparams.shards + rsparams.parity, 1, (n, done) =&gt; { const pad = (n) =&gt; n &gt;= 10 ? n.toString() : `0${n}`; const shardpath = path.join(path.dirname(filepath), `${pad(n)}.shard`); const bufferSlice = file.slice(position, position + rsparams.size); fs.writeFile(shardpath, bufferSlice, () =&gt; { position += rsparams.size; shards.push({ index: n, size: rsparams.size, path: shardpath }); done(); }); }, () =&gt; { fs.unlink(filepath, () =&gt; prepareContracts()); }); }; const uploadShards = (shards, object, callback) =&gt; { let completed = 0; async.eachLimit(shards, 3, (shard, next) =&gt; { async.retry({ times: 10 }, (done) =&gt; { this._pluckStorageProvider(shard.size, (err, target) =&gt; { if (err) { return done(err); } let proposal = shard.proposal; let rs = fs.createReadStream(shard.path); this.node.logger.info(`requesting upload to ${target[0]}`); this.notifyClients( 'TRANSFER_UP_INFO', object.hash, `Requesting upload channel from ${target[1].hostname}`, { target, shard: proposal.shardHash } ); this._createUploadChannel({ stream: rs, target, proposal: proposal.toObject(), shard }, (err) =&gt; { if (err) { this.node.logger.warn(`shard upload failed, ${err.message}`); this.notifyClients( 'TRANSFER_UP_FAIL', object.hash, `Failed upload channel with ${target[1].hostname}`, { target, shard: proposal.shardHash, error: err.message } ); return this._markPeerAsFailed(target, () =&gt; done(err)); } this.notifyClients( 'TRANSFER_UP_PASS', object.hash, `Uploaded ${shard.hash} to ${target[1].hostname}`, { shard: shard.hash, total: shards.length, complete: ++completed } ); done(); }); }); }, next); }, (err) =&gt; { object.shards = shards; if (err) { object.status = 'failed'; this.node.logger.error(err.message); object.save(() =&gt; callback(err)); } else { object.status = 'finished'; this.node.logger.info(`successfully uploaded ${object.hash}`); this.node.logger.info(`removing stage ${path.dirname(filepath)}`); rimraf(path.dirname(filepath), (err) =&gt; { /* istanbul ignore if */ if (err) { this.node.logger.error(err.message); } object.save(() =&gt; callback(null, object)); }); } }); } const distributePointer = (object, callback) =&gt; { const { blob, hash } = object.toEncryptedBlob(); const key = hash.toString('hex'); const encoded = blob.toString('base64'); this.node.iterativeStore(key, encoded, (err, stored) =&gt; { if (stored &lt; 3) { this.node.logger.warn( `failed to fully distribute pointer (${stored} of 3)` ); } callback(null, object); }); }; async.waterfall([ (next) =&gt; encodeErasure(next), (file, rs, obj, next) =&gt; prepareShards(file, rs, obj, next), (shards, obj, next) =&gt; uploadShards(shards, obj, next) ], (err, object) =&gt; { if (err) { return callback(err); } distributePointer(object, () =&gt; { this.node.logger.info('finished pointer distribution'); }); callback(null, object); }); } /** * Downloads the object from the network * @param {object} request * @param {object} response * @param {function} next */ downloadObject(req, res, next) { this._downloadObject(req.params.id, (err, buffer, object, info) =&gt; { /* istanbul ignore if */ if (err) { return next(err); } const { rsparams } = info; const decipher = utils.createDecipher( Buffer.from(object.ecpub, 'hex'), Buffer.from(object.ecprv, 'hex') ); decipher.on('error', (err) =&gt; { this.node.logger.error(err.message); res.end(); }); res.writeHead(200, { 'Content-Type': object.mimetype, 'Content-Length': object.size, 'Transfer-Encoding': '' }); decipher.pipe(slice(0, object.size - rsparams.padding)).pipe(res); decipher.end(buffer); }); } /** * @private * @param {string} id * @param {function} callback */ _downloadObject(id, next) { let targets = 0; let failed = []; let buffer = null; let object = null; let completed = 0; function updateRecovery(shard, i) { let recovery = { shard, offset: shard.size * i, length: (shard.size * i) + shard.size }; failed.push(recovery); buffer.fill(0, recovery.offset, recovery.length); targets |= (1 &lt;&lt; i); } const downloadShard = (shard, token, i, callback) =&gt; { this.notifyClients( 'TRANSFER_DOWN_INFO', object.hash, `Requesting download channel from ${shard.service[1].hostname}`, { shard: shard.hash } ); let downloadStream = utils.createShardDownloader( shard.service, shard.hash, token, this.node.onion.createClearAgent() ); let tmpBuffer = Buffer.from([]); downloadStream.on('error', (err) =&gt; { this.notifyClients( 'TRANSFER_DOWN_FAIL', object.hash, `Failed upload channel with ${shard.service[1].hostname}`, { shard: shard.hash, error: err.message } ); this.node.logger.warn( `failed to download, reason: ${err.message}` ); updateRecovery(shard, i); callback(); }); downloadStream.on('data', (data) =&gt; { tmpBuffer = Buffer.concat([tmpBuffer, data]); }); downloadStream.on('end', () =&gt; { this.notifyClients( 'TRANSFER_DOWN_PASS', object.hash, `Donwloaded ${shard.hash} from ${shard.service[1].hostname}`, { shard: shard.hash, total: object.shards.length, complete: ++completed } ); buffer.fill(tmpBuffer, shard.size * i, (shard.size * i) + shard.size); callback(); }); }; const assembleShards = (object, size, rs, callback) =&gt; { let done = (err) =&gt; callback(err, buffer); try { rs.decode(buffer, 0, size, object.shards[0].size, 0, object.shards[0].size, targets, done); } catch (err) { /* istanbul ignore next */ callback(err); } }; this.database.ObjectPointer.findOne({ _id: id }, (err, result) =&gt; { object = result; /* istanbul ignore if */ if (err || !object) { return next(err || new Error('Not found')); } /* istanbul ignore if */ if (object.status !== 'finished') { return next(new Error( 'Cannot fetch object that did not complete upload' )); } let size = object.shards.reduce( (a, b) =&gt; ({ size: a.size + b.size }), { size: 0 } ).size; let rsparams = utils.getErasureParameters(size); let rs = new ReedSolomon(rsparams.shards, rsparams.parity); /* istanbul ignore if */ if (size &gt; BUFFER.kMaxLength) { return next(new Error( `File size exceeds max supported (${bytes(BUFFER.kMaxLength)})` )); } buffer = Buffer.alloc(size); async.eachOfLimit(object.shards, 3, (shard, i, done) =&gt; { this.node.authorizeRetrieval( shard.service, [shard.hash], (err, result) =&gt; { if (err) { this.node.logger.warn(err.message); updateRecovery(shard, i); return done(); } downloadShard(shard, result[0], i, done); } ); }, () =&gt; { assembleShards(object, size, rs, err =&gt; { /* istanbul ignore if */ if (err) { return next(err); } const decipher = utils.createDecipher( Buffer.from(object.ecpub, 'hex'), Buffer.from(object.ecprv, 'hex') ); decipher.on('error', (err) =&gt; { this.node.logger.error(err.message); }); decipher.pipe(slice(0, object.size - rsparams.padding)), decipher.end(buffer); next(null, buffer, object, { failed, rsparams } ); }); }); }); } /** * Ends contracts with farmers for the object parts and removes * reference to them * @param {object} request * @param {object} response * @param {function} next */ destroyObject(req, res, next) { let id = req.params.id; this.database.ObjectPointer.findOne({ _id: id }, (err, object) =&gt; { /* istanbul ignore if */ if (err) { return next(err); } async.each(object.shards, (shard, done) =&gt; { this.database.ShardContract.remove({ shardHash: shard.hash }, (err) =&gt; { /* istanbul ignore if */ if (err) { this.node.logger.error( `failed to remove shard contract ${shard.hash}` ); } done(); }); }, () =&gt; { // NB: If we are deleting a pointer to a queued object, // NB: make sure we clean up let tmp = path.join(this.options.tempStagingDirectory, object.hash); if (fs.existsSync(tmp)) { try { rimraf.sync(tmp); } catch (err) { /* istanbul ignore next */ this.node.logger.error(err.message); } } object.remove((err) =&gt; { /* istanbul ignore if */ if (err) { return next(err); } res.status(201).send(); }) }); }); } /** * Returns the magnet link for the given object * @param {object} request * @param {object} response * @param {function} next */ getObjectMagnet(req, res, next) { const { id } = req.params; this.database.ObjectPointer.findOne({ _id: id }, (err, object) =&gt; { /* istanbul ignore if */ if (err || !object) { return next(err || new Error('Object not found')); } const { magnet } = object.toEncryptedBlob(); res.status(200).json({ href: magnet }); }); } /** * Accepts a body containing a magnet link, resolves the pointer and creates * a local object pointer record, then returns it. Clients can follow with a * GET /:id to download the object * @param {object} request * @param {object} response * @param {function} next */ resolveObject(req, res, next) { req.on('error', next).pipe(concat((body) =&gt; { let parsed, key; try { parsed = qs.parse(url.parse(body.toString()).query); key = Buffer.from(parsed.xt.substr(8), 'hex').toString('hex'); } catch (err) { /* istanbul ignore next */ return next(new Error('Failed to parse magnet link')); } this.node.iterativeFindValue(key, (err, result) =&gt; { /* istanbul ignore if */ if (err || result.length &gt;= 0) { return next(err || new Error('Failed to resolve magnet')); } let decipher, cleartext; try { decipher = crypto.createDecipher( 'aes256', Buffer.from(parsed['x.pword'], 'hex') ); cleartext = JSON.parse(Buffer.concat([ decipher.update(Buffer.from(result.value, 'base64')), decipher.final() ]).toString('utf8')); } catch (err) { /* istanbul ignore next */ return next(new Error('Failed to decrypt pointer')); } let object = new this.database.ObjectPointer(merge(cleartext, { ecprv: parsed['x.ecprv'], _isOwner: false })); object.save((err) =&gt; { /* istanbul ignore if */ if (err) { return next(err); } res.status(200).json(object.toObject()); }); }); })); } /** * Periodically call this to scan the object store for shards that need to * be audited * @param * @param {function} callback */ audit(callback = () =&gt; null) { const opportunities = constants.SCORE_INTERVAL / constants.AUDIT_INTERVAL; const query = { _lastAuditTimestamp: { $lt: Date.now() - constants.SCORE_INTERVAL }, _isOwner: true }; this.node.logger.info('starting audit routine'); this.database.ObjectPointer.find(query, (err, objects) =&gt; { /* istanbul ignore if */ if (err) { return callback(err); } const total = Math.ceil(objects.length / opportunities); const candidates = []; while (candidates.length !== total) { candidates.push(knuthShuffle(objects).pop()); } this.node.logger.info(`preparing ${candidates.length} objects for audit`); async.eachSeries( candidates, (obj, next) =&gt; this._auditObject(obj, next), (err) =&gt; { /* istanbul ignore if */ if (err) { this.node.logger.warn(err.message); return callback(err); } this.emit('auditInternalFinished'); callback(); } ); }); } /** * @private */ _createUploadChannel({ stream, target, proposal, shard }, done) { this.node.claimProviderCapacity(target, proposal, (err, data) =&gt; { if (err) { this.node.logger.warn( `failed to claim capacity, reason: ${err.message}` ); return done(err); } this.node.logger.info(`capacity claimed from ${target[0]}`); let [completedContract, consignToken] = data; let uploadStream = utils.createShardUploader( target, completedContract.shardHash, consignToken, this.node.onion.createClearAgent() ); completedContract = new this.database.ShardContract( completedContract ); uploadStream.on('error', done); uploadStream.on('response', (res) =&gt; { let body = ''; res.on('data', (data) =&gt; body += data.toString()); res.on('end', () =&gt; { /* istanbul ignore if */ if (res.statusCode !== 200) { this.node.logger.warn( `failed to upload shard, reason: ${body}` ); return done(new Error(body)); } this.node.logger.debug(`shard uploaded to ${target[0]}`); delete shard.proposal; delete shard.path; shard.service = target; shard.hash = completedContract.shardHash; completedContract.save((err) =&gt; done(err)); }); }); stream.on('data', (data) =&gt; uploadStream.write(data)) .on('end', () =&gt; uploadStream.end()) .on('error', (err) =&gt; { /* istanbul ignore next */ uploadStream.removeAllListeners(); /* istanbul ignore next */ done(err); }); }); } /** * @private */ _auditObject(object, callback) { this.node.logger.info(`auditing object ${object.hash}`); async.mapLimit(object.shards, 3, (shard, done) =&gt; { this.database.ShardContract.findOne({ shardHash: shard.hash }, (err, contract) =&gt; { /* istanbul ignore if */ if (err) { done(err); } else if (shard.audits.challenges.length === 0) { this.node.logger.info(`regenerating challenges for ${shard.hash}`); this._regenerateChallenges(shard, (err) =&gt; { object.save(() =&gt; done(err, [shard, contract])); }); } else { done(null, [shard, contract]) } }); }, (err, results) =&gt; { /* istanbul ignore if */ if (err) { return callback(err); } async.eachLimit(results, 3, ([shard, contract], done) =&gt; { let challenge = shard.audits.challenges.shift(); let audits = [{ hash: shard.hash, challenge }]; let contact = [ shard.service[0], this.node.router.getContactByNodeId( shard.service[0] ) || shard.service[1] ]; contract._lastAuditTimestamp = Date.now(); this.node.auditRemoteShards(contact, audits, (err, proofs) =&gt; { const fail = (err, expected, actual) =&gt; { shard.decayed = true; const report = new this.database.AuditReport({ reporter: this.node.identity.toString('hex'), provider: contract.providerIdentity, challenge, expected, actual }); this.node.logger.warn(err.message); report.save(() =&gt; contract.save(() =&gt; done())); }; /* istanbul ignore if */ if (err) { return fail(err); } const pass = (report) =&gt; { report.save(() =&gt; contract.save(() =&gt; done())); }; let { proof } = proofs.pop() || { proof: [] }; let [actual, expected] = Proof.verify( proof, Buffer.from(shard.audits.root, 'hex'), shard.audits.depth ); if (Buffer.compare(expected, actual) !== 0) { return fail(new Error('Audit response failed verification'), expected.toString('hex'), actual.toString('hex')); } const report = new this.database.AuditReport({ reporter: this.node.identity.toString('hex'), provider: contract.providerIdentity, challenge, expected: expected.toString('hex'), actual: actual.toString('hex') }); if (shard.audits.challenges.length === 0) { this._regenerateChallenges(shard, () =&gt; pass(report)); } else { pass(report); } }); }, () =&gt; { object.save((err) =&gt; { /* istanbul ignore if */ if (err) { return callback(err); } /* istanbul ignore else */ if (object.percentDecayed &gt;= 0.15) { let threshold = Math.ceil(constants.MAX_DECAY * 100).toFixed(); let decay = Math.ceil(object.percentDecayed * 100).toFixed(); this.node.logger.info( `object decay more than ${threshold}% (${decay}%), will rebuild` ); this._rebuildObject(object, callback); } else { callback(); } }); }); }); } /** * @private */ _rebuildObject(object, callback = () =&gt; null) { this.node.logger.info(`rebuilding object ${object.id}`); this._downloadObject(object.id, (err, buffer, object, info) =&gt; { /* istanbul ignore if */ if (err) { this.node.logger.error(`failed to download object, ${err.message}`); return callback(err); } const { failed, rsparams } = info; async.eachLimit(failed, 3, (recovery, done) =&gt; { const { shard, offset, length } = recovery; const auditStream = new AuditStream(constants.NUM_CHALLENGES); const slice = buffer.slice(offset, length); auditStream.on('error', done).on('finish', () =&gt; { const record = auditStream.getPrivateRecord(); shard.audits = {}; shard.audits.challenges = record.challenges; shard.audits.depth = record.depth; shard.audits.root = record.root.toString('hex'); const proposal = new this.database.ShardContract({ shardHash: shard.hash, shardSize: rsparams.size, auditLeaves: auditStream.getPublicRecord(), ownerParentKey: this.node.contact.xpub, ownerIndex: this.node.contact.index, ownerIdentity: this.node.identity.toString('hex'), accessPolicies: object.policies }); this._pluckStorageProvider(shard.size, (err, target) =&gt; { /* istanbul ignore if */ if (err) { return done(err); } shard.service = target; this.database.ShardContract.remove({ shardHash: shard.hash, ownerIdentity: { $not: { $eq: this.node.identity.toString('hex') } } }, () =&gt; { this._createUploadChannel({ stream: utils.bufferAsReadableStream(slice), proposal: proposal.toObject(), target, shard }, (err) =&gt; { /* istanbul ignore if */ if (err) { this.node.logger.error(err.message) } else { this.node.logger.info(`shard ${shard.hash} redistributed`); } done(err); }); }); }); }); auditStream.end(slice); }, () =&gt; object.save(callback)); }); } /** * @private * @param {number} size * @param {function} callback */ _pluckStorageProvider(size, callback) { this.database.PeerProfile.find({ updated: { $gt: Date.now() - this.options.providerCapacityPoolTimeout }, 'capacity.available': { $gt: size }, identity: { $ne: this.node.identity.toString('hex') }, $or: [ { _failed: { $lt: Date.now() - this.options.providerFailureBlacklistTimeout } }, { _failed: { $exists: false } } ] }, (err, profiles) =&gt; { /* eslint max-statements: [2, 20] */ if (err) { this.node.logger.error(err.message); this.node.logger.warn('failed to load capacity cache'); profiles = []; } let target = undefined; let contact = undefined; knuthShuffle(profiles); for (let i = 0; i &lt; profiles.length; i++) { contact = this.node.router.getContactByNodeId( profiles[i].identity ); target = contact ? [profiles[i].identity, contact] : [profiles[i].identity, profiles[i].contact]; /* istanbul ignore else */ if (target !== undefined) { break; } } if (target === undefined) { this.node.logger.warn( 'not enough capacity data collected to upload' ); callback(new Error('Not enough capacity information')); } else { callback(null, target); } }); } /** * @private */ _regenerateChallenges(shard, callback = () =&gt; null) { const auditStream = new AuditStream(constants.NUM_CHALLENGES); this.node.authorizeRetrieval(shard.service, [shard.hash], (err, result) =&gt; { /* istanbul ignore if */ if (err) { return callback(err); } const downloadStream = utils.createShardDownloader( shard.service, shard.hash, result[0], this.node.onion.createClearAgent() ); downloadStream.pipe(auditStream).on('finish', () =&gt; { const record = auditStream.getPrivateRecord(); shard.audits = {}; shard.audits.challenges = record.challenges; shard.audits.depth = record.depth; shard.audits.root = record.root.toString('hex'); this.node.database.ShardContract.findOne({ shardHash: shard.hash }, (err, contract) =&gt; { /* istanbul ignore if */ if (err) { return callback(err); } contract.auditLeaves = auditStream.getPublicRecord(); contract.sign('owner', this.node.spartacus.privateKey); contract.save((err) =&gt; { /* istanbul ignore if */ if (err) { return callback(err); } this.node.requestContractRenewal(shard.service, contract.toObject(), callback); }); }); }).on('error', callback); }); } /** * Set the date of _failed on the peer profile * @private */ _markPeerAsFailed([identity], callback) { this.database.PeerProfile.update({ identity }, { $set: { _failed: Date.now() } }, callback); } /** * Takes all audit reports and reaps them while applying their results to * local peer profile reputation score, then publishes the compressed * payload to the bootstrap directory * @param {function} callback */ scoreAndPublishAuditReports(callback = () =&gt; null) { const payload = []; const profiles = new Set(); const cursor = this.database.AuditReport.find({}).cursor(); const worker = (report, done) =&gt; { const { reporter, provider } = report; payload.push(report.toCompressedAuthenticated( this.node.spartacus.privateKey )); this.database.PeerProfile.count({ identity: { $in: [reporter, provider] } }, (err, count) =&gt; { /* istanbul ignore if */ if (count !== 2) { this.node.logger.warn( 'skipping score application for unknown peer(s)' ); return done(); } profiles.add(reporter); profiles.add(provider); this._applyScore(report, () =&gt; done()); }); }; const queue = async.queue(worker, 1); queue.drain = () =&gt; { this.node.reportAuditResults(payload, (err) =&gt; { /* istanbul ignore if */ if (err) { this.node.logger.warn(err.message); } async.series([ // NB: Keep track of reporting streaks (done) =&gt; { this.database.PeerProfile.update({ identity: { $in: [...profiles] } }, { $inc: { '_reports.streak': 1 }, $set: { '_reports.missed': 0 } }, done); }, // NB: Keep track of missed reports (done) =&gt; { this.database.PeerProfile.update({ identity: { $not: { $in: [...profiles] } } }, { $set: { '_reports.streak': 0 }, $inc: { '_reports.missed': 1 } }, done); }, // NB: Apply reward for 10+ streak (done) =&gt; { this.database.PeerProfile.update({ '_reports.streak': { $gte: 10 } }, { $inc: { 'reputation.score': 6 } }, done); }, // NB: Apply penalty for 2+ missed (done) =&gt; { this.database.PeerProfile.update({ '_reports.missed': { $gt: 2 }, }, { $inc: { 'reputation.score': -3 } }, done); }, // NB: Rebalance any negative scores (done) =&gt; { this.database.PeerProfile.update({ 'reputation.score': { $lt: 0 } }, { $set: { 'reputation.score': 0 } }, done); }, // NB: Clean up all consumed reports (done) =&gt; { this.database.AuditReport.remove({}, done); } ], callback); }); }; cursor.on('data', (report) =&gt; queue.push(report)).on('error', callback); } /** * @private */ _applyScore(auditReport, callback) { async.series([ // NB: Reporter loses 1 per report (done) =&gt; { this.database.PeerProfile.findOneAndUpdate({ identity: auditReport.reporter }, { $inc: { 'reputation.score': -1 } }, done); }, // NB: Reporter gains 1 per positive report (done) =&gt; { if (auditReport.expected === auditReport.actual) { this.database.PeerProfile.findOneAndUpdate({ identity: auditReport.reporter }, { $inc: { 'reputation.score': 1 } }, done); } else { done(); } }, // NB: Reporter gains 1 if another peer reports the same outcome (done) =&gt; { this.database.AuditReport.findOne({ provider: auditReport.provider, reporter: { $not: { $eq: auditReport.reporter } } }, (err, corroboratedReport) =&gt; { if (err || !corroboratedReport) { done(); } else if (auditReport.outcome === corroboratedReport.outcome) { this.database.PeerProfile.findOneAndUpdate({ identity: auditReport.reporter }, { $inc: { 'reputation.score': 1 } }, done); } else { done(); } }); }, // NB: Reporter gains 1 if the provider reported on them too (done) =&gt; { this.database.AuditReport.findOne({ reporter: auditReport.provider, provider: auditReport.reporter }, (err, mutualReport) =&gt; { if (mutualReport) { this.database.PeerProfile.findOneAndUpdate({ identity: auditReport.reporter }, { $inc: { 'reputation.score': 1 } }, done); } else { done(); } }); } ], () =&gt; callback()); } /** * @private */ getReputationImpact(req, res, next) { this.getPeerReputationScore(req.params.id, (err, result) =&gt; { /* istanbul ignore if */ if (err) { return next(err); } res.status(200).send(result); }); } /** * Calculates the percentile and relative usage allowance of the given identity * @param {string} identity - 160 bit node identity key * @param {Directory~getPeerReputationScoreCallback} callback */ getPeerReputationScore(identity, callback) { let target, highest, capacity, percentile, allowance, score, peers = {}; async.series([ (next) =&gt; { this._getPeerProfileById(identity, (err, profile) =&gt; { target = profile; score = target ? target.reputation.score : 0; /* istanbul ignore if */ if (!profile) { err = new Error('Profile not found'); err.code = 404; } next(err); }); }, (next) =&gt; { this._getHighestScoringPeer((err, profile) =&gt; { highest = profile; next(err); }); }, (next) =&gt; { this._getTotalKnownNetworkCapacity((err, result) =&gt; { capacity = result; next(err); }) }, (next) =&gt; { async.parallel([ (done) =&gt; this.database.PeerProfile.count({ 'reputation.score': { $gte: target.reputation.score } }, (err, count) =&gt; { peers.upper = count; done(err); }), (done) =&gt; this.database.PeerProfile.count({ 'reputation.score': { $lte: target.reputation.score } }, (err, count) =&gt; { peers.lower = count; done(err); }) ], next); }, (next) =&gt; { percentile = score / (highest.reputation.score || 1); percentile = parseFloat(percentile.toFixed(2)); if (percentile &lt; 0.2) { allowance = Math.floor((0.05 * capacity.available) / peers.lower); } else if (percentile &gt; 0.2 &amp;&amp; percentile &lt; 0.5) { allowance = Math.floor((0.20 * capacity.available) / peers.lower); } else { allowance = Math.floor((0.75 * capacity.available) / peers.upper); } next(); } ], (err) =&gt; callback(err, { identity, percentile, allowance, score, capacity })); } /** * @callback Directory~getPeerReputationScoreCallback * @param {object|null} error * @param {object} result * @param {number} result.score - Numberical repuation score * @param {number} result.percentile - Percent of scores identity exceeds * @param {number} result.allowance - Bytes identity is allowed to claim */ /** * @private */ _getTotalKnownNetworkCapacity(callback) { let allocated, available; this.database.PeerProfile .aggregate([ { $match: { updated: { $gte: new Date(Date.now() - ms('24HR')) } } }, { $group: { _id: null, available: { $sum: '$capacity.available' }, allocated: { $sum: '$capacity.allocated' } } } ]) .cursor({}) .exec() .on('data', data =&gt; { allocated = data.allocated; available = data.available; }) .on('error', callback) .on('end', () =&gt; callback(null, { allocated, available })); } /** * Get the peer with the highest reputation score * @private */ _getHighestScoringPeer(callback) { this.database.PeerProfile .find({}) .sort({ 'reputation.score': -1 }) .exec((err, results) =&gt; { /* istanbul ignore if */ if (err) { return callback(err); } /* istanbul ignore if */ if (!results.length) { return callback(new Error('Failed to load peer profile')); } callback(null, results[0]); }); } /** * @private */ _getPeerProfileById(identity, callback) { this.database.PeerProfile.findOne({ identity }, callback); } /** * @private */ listProfiles(req, res, next) { let now = Date.now(); this.database.PeerProfile.find({ updated: { $gt: now - ms('24HR') } }, [], { sort: { updated: -1 } }, (err, results) =&gt; { /* istanbul ignore if */ if (err) { return next(err); } res.writeHead(200, { 'Content-Type': 'application/json' }); res.end(JSON.stringify(results.map((r) =&gt; r.toObject()))); }); } /** * @private */ getProfile(req, res, next) { this._getPeerProfileById(req.params.identity, (err, profile) =&gt; { /* istanbul ignore if */ if (err) { return next(err); } if (!profile) { res.writeHead(404); res.end('Profile not known'); } else { res.writeHead(200, { 'Content-Type': 'application/json' }); res.end(JSON.stringify(profile.toObject())); } }); } } module.exports = Bridge; × Search results Close "},"database.js.html":{"id":"database.js.html","title":"Source: database.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: database.js 'use strict'; const ms = require('ms'); const { Readable: ReadableStream } = require('stream'); const { EventEmitter } = require('events'); const mongoose = require('mongoose'); const { Schema, createConnection } = mongoose; const utils = require('./utils'); const secp256k1 = require('secp256k1'); const { utils: keyutils } = require('kad-spartacus'); const crypto = require('crypto'); const stringify = require('json-stable-stringify'); mongoose.Promise = Promise; /** * Describes a known network peer * @constructor * @param {object} properties * @param {string} properties.identity - Hexidecimal identity key * @param {object} properties.contact * @param {string} properties.contact.hostname - Onion service address * @param {number} properties.contact.port - Onion service virtual port * @param {string} [properties.contact.protocol=https:] - Transport protocol * @param {string} properties.contact.xpub - HD public extended key * @param {number} properties.contact.index - Indentity key derivation index * @param {string} [properties.contact.agent] - User agent identifier * @param {object} properties.capacity * @param {number} properties.capacity.timestamp - Last capacity publication * @param {number} properties.capacity.available - Bytes available at host * @param {number} properties.capacity.allocated - Bytes allocated by host * @param {object} properties.reputation * @param {number} properties.reputation.score - Audit based reputation score * @param {number} properties.reputation.timestamp - Last scoring time * @param {number} properties.updated - Timestamp of last profile update * @memberof Database */ const PeerProfile = new Schema({ identity: { type: String, required: true, unique: true, min: 20, max: 20 }, contact: { hostname: { type: String, required: true }, port: { type: Number, required: true }, protocol: { type: String, required: true, default: 'https:' }, xpub: { type: String, required: true }, index: { type: Number, required: true, default: 0 }, agent: { type: String, default: 'unknown' } }, capacity: { allocated: { type: Number, default: 0 }, available: { type: Number, default: 0 } }, reputation: { score: { type: Number, default: 0, min: 0 }, timestamp: { type: Date, default: Date.now } }, updated: { type: Date, default: Date.now }, _reports: { missed: { type: Number, default: 0 }, streak: { type: Number, default: 0 } }, _failed: { type: Date, default: 0 } }); PeerProfile.set('toObject', { transform: function(doc, ret) { delete ret._id; delete ret.__v; delete ret._reports; delete ret._failed; } }); /** * Returns a human readable string URI for the peer * @returns {string} */ PeerProfile.methods.toString = function() { return [ this.contact.protocol, '//', this.contact.hostname, ':', this.contact.port ].join(''); }; /** * Describes the result of an audit as a report to directories * @constructor * @param {object} properties * @param {string} properties.reporter - Identity key of the reporter * @param {string} properties.provider - Identity key of the provider * @param {string} properties.challenge - Challenge key given to provider * @param {string} properties.expected - Expected challenge response * @param {string} properties.actual - Actual challenge response * @memberof Database */ const AuditReport = new Schema({ reporter: { type: String, required: true, match: new RegExp('[A-Fa-f0-9]{40}$') }, provider: { type: String, required: true, match: new RegExp('[A-Fa-f0-9]{40}$') }, challenge: { type: String, required: true }, expected: { type: String, required: true, match: new RegExp('[A-Fa-f0-9]{40}$') }, actual: { type: String, required: true, match: new RegExp('[A-Fa-f0-9]{40}$') } }); AuditReport.virtual('outcome').get(function() { return this.expected === this.actual ? 1 : 0; }); /** * Returns a serialized and cryptographically signed version of this report * @param {buffer} privateKey - SECP256K1 private key * @returns {string[]} */ AuditReport.methods.toCompressedAuthenticated = function(privateKey) { let compressed, { signature, recovery } = secp256k1.sign( utils.sha256(Buffer.from(this.getSigningArray().join(''), 'hex')), privateKey ); signature = Buffer.concat([Buffer.from([recovery]), signature]); compressed = this.getSigningArray(); compressed.push(signature.toString('base64')); return compressed; }; /** * Returns the array of keys needed to sign the report * @returns {string[]} */ AuditReport.methods.getSigningArray = function() { return [ this.reporter, this.provider, this.challenge, this.expected, this.actual ]; }; /** * Verifies the signature of a compressed and authenticated report * @param {string[]} compressed - The compressed report * @returns {boolean} */ AuditReport.statics.verifyCompressedAuthenticated = function(compressed) { const report = new this({ reporter: compressed[0], provider: compressed[1], challenge: compressed[2], expected: compressed[3], actual: compressed[4] }); if (report.validateSync()) { return false; } const compactSig = Buffer.from(compressed[5], 'base64'); const recovery = compactSig[0]; const signature = compactSig.slice(1); const message = utils.sha256(Buffer.from( report.getSigningArray().join(''), 'hex' )); const pubkey = secp256k1.recover(message, signature, recovery, true); const pubkeyhash = report.reporter; return secp256k1.verify(message, signature, pubkey) &amp;&amp; keyutils.toPublicKeyHash(pubkey).toString('hex') === pubkeyhash; }; /** * Describes a contract between two peers for shard storage * @constructor * @param {object} properties * @param {number} [properties.version=2] - Version of the contract type * @param {string} properties.ownerParentKey - HD key for the shard owner * @param {number} [properties.ownerIndex=0] - HD index for the shard owner * @param {string} properties.ownerIdentity - Identity key of the shard owner * @param {string} properties.ownerSignature - Valid signature from owner * @param {string} properties.providerParentKey - HD key for the shard owner * @param {number} [properties.providerIndex=0] - HD index for the shard owner * @param {string} properties.providerIdentity - Identity key of the shard owner * @param {string} properties.providerSignature - Valid signature from provider * @param {number} properties.shardSize - Number of bytes in the shard * @param {string} properties.shardHash - RMD160 SHA256 hash of shard * @param {string[]} properties.auditLeaves - Lower leaves of audit merkle tree * @param {number} properties.auditInterval - Expect a challenge every N ms * @param {string[]} properties.accessPolicies - IMP-10 access policy strings * @param {string} [properties.fundingDestination=none] - Reserved for future * @memberof Database */ const ShardContract = new Schema({ version: { type: Number, required: true, default: 2 }, ownerParentKey: { type: String, required: true, match: new RegExp('^[1-9a-km-zA-HJ-NP-Z]{1,111}$') }, ownerIndex: { type: Number, required: true, default: 0, min: 0, max: 2147483647 }, ownerIdentity: { type: String, required: true, match: new RegExp('[A-Fa-f0-9]{40}$') }, ownerSignature: { type: String }, providerParentKey: { type: String, required: true, match: new RegExp('^[1-9a-km-zA-HJ-NP-Z]{1,111}$') }, providerIndex: { type: Number, required: true, default: 0, min: 0, max: 2147483647 }, providerIdentity: { type: String, required: true, match: new RegExp('[A-Fa-f0-9]{40}$') }, providerSignature: { type: String }, shardSize: { type: Number, required: true, min: 0 }, shardHash: { type: String, required: true, match: new RegExp('^[0-9a-f]{40}$') }, auditLeaves: [{ type: String, match: new RegExp('[A-Fa-f0-9]$') }], auditInterval: { type: Number, required: true, default: ms('60H') }, accessPolicies: [{ type: String }], fundingDestination: { type: String, default: 'none' }, _lastAuditTimestamp: { type: Date, default: Date.now }, _lastFundingTimestamp: { type: Date, default: Date.now }, _lastAccessTimestamp: { type: Date, default: Date.now } }); ShardContract.index({ shardHash: 1, providerIdentity: 1, ownerIdentity: 1 }); ShardContract.set('toObject', { virtuals: false, transform: function(doc, ret) { delete ret._lastAuditTimestamp; delete ret._lastAccessTimestamp; delete ret._lastFundingTimestamp; delete ret._id; delete ret.__v; } }); /** * Returns the stringified version of the contract for signing * @returns {string} */ ShardContract.methods.getSigningString = function() { const obj = this.toObject(); delete obj.ownerSignature; delete obj.providerSignature; return JSON.stringify(obj); }; /** * Creates a signature of the contract given the SECP256K1 key * @returns {string} */ ShardContract.methods.signExternal = function(secret) { const { signature, recovery } = secp256k1.sign( utils.sha256(Buffer.from(this.getSigningString())), secret ); return Buffer.concat([Buffer.from([recovery]), signature]); }; /** * Verifies the signature against a given public key * @returns {boolean} */ ShardContract.methods.verifyExternal = function(signature, pubkey) { return secp256k1.verify( utils.sha256(Buffer.from(this.getSigningString())), signature, pubkey ); }; /** * Verifies that the given actor signature is valid * @param {string} actor - One of provider|owner * @returns {boolean} */ ShardContract.methods.verify = function(actor) { const compactSig = Buffer.from(this[`${actor}Signature`], 'base64'); const recovery = compactSig[0]; const signature = compactSig.slice(1); const message = utils.sha256(Buffer.from(this.getSigningString())); const pubkey = secp256k1.recover(message, signature, recovery, true); const pubkeyhash = this[`${actor}Identity`]; return this.verifyExternal(signature, pubkey) &amp;&amp; keyutils.toPublicKeyHash(pubkey).toString('hex') === pubkeyhash; }; /** * Applies signature to contract as the given actor * @param {string} actor - One of provider|owner * @param {buffer} secret - SECP256K1 private key * @returns {string} */ ShardContract.methods.sign = function(actor, secret) { return this[`${actor}Signature`] = this.signExternal(secret) .toString('base64'); }; /** * Returns the property names that are different between two contracts * @returns {string[]} */ ShardContract.statics.diff = function(c1, c2) { const differs = []; c1 = c1.toObject(); c2 = c2.toObject(); for (let prop in c1) { if (Array.isArray(c1[prop])) { if (JSON.stringify(c1[prop]) !== JSON.stringify(c2[prop])) { differs.push(prop); } } else if (c1[prop] !== c2[prop]) { differs.push(prop); } } return differs; }; ShardContract.TYPE_GROUP = 'G'; ShardContract.TYPE_USER = 'U'; /** * Returns which, if any, methods are allowed by the access policy for the * given contact * @param {object} contact * @param {string} contact.0 - Identity key * @param {object} contact.1 - Contact information * @returns {string[]} */ ShardContract.methods.checkAccessPolicy = function(contact) { let [identity, info] = contact; let allowed = []; if (this.ownerIdentity === identity || this.ownerParentKey === info.xpub) { return ['CONSIGN', 'RETRIEVE', 'RENEW', 'AUDIT', 'MIRROR']; } for (let p = 0; p &lt; this.accessPolicies.length; p++) { let policy = this.accessPolicies[p].split(':'); let [type, key, permissions] = policy; if (!type &amp;&amp; !key) { allowed = allowed.concat(permissions.split(',')); } if (type === ShardContract.TYPE_GROUP &amp;&amp; key === info.xpub) { allowed = allowed.concat(permissions.split(',')); } if (type === ShardContract.TYPE_USER &amp;&amp; key === identity) { allowed = allowed.concat(permissions.split(',')); } } return allowed; }; /** * Keeps references to the location of shards that compose an object * @constructor * @memberof Database * @param {object} properties * @param {string} [properties.name=untitled.blob] - Human readable object name * @param {string} [properties.encoding] - File encoding type * @param {string} [properties.mimetype=application/octet] - MIME type * @param {string} properties.hash - SHA-256 hash of the object * @param {number} properties.size - Number of bytes in the object * @param {string} properties.status - One of finished|queued|failed * @param {object[]} properties.shards * @param {number} properties.shards.size - Number of bytes in shard * @param {string} properties.shards.hash - RMD160 hash of shard * @param {object} properties.shards.service * @param {string} properties.shards.service.0 - Identity key of provider * @param {object} properties.shards.service.1 - Contact info of provider * @param {boolean} properties.shards.decayed - Flag if this shard is lost * @param {object} properties.audits * @param {string} properties.audits.root - Merkle root for audit tree * @param {string[]} properties.audit.challenges - Audit challenges for shard * @param {number} properties.audit.depth - Depth of audit merkle tree * @param {string} properties.ecpub - SECP256K1 public key object is encrypted * @param {string} properties.ecprv - SECP256K1 private key object is encrypted * @param {string[]} properties.policies - List of IMP-10 access policies */ const ObjectPointer = new Schema({ name: { type: String, default: 'untitled.blob' }, encoding: { type: String }, mimetype: { type: String, default: 'application/octet-stream' }, hash: { type: String, required: true, min: 64, max: 64 }, size: { type: Number, required: true }, status: { type: String, required: true, enum: ['finished', 'queued', 'failed'] }, shards: [{ size: { type: Number, required: true, min: 1 }, hash: { type: String, required: true }, service: [Schema.Types.Mixed], decayed: { type: Boolean, default: false }, audits: { root: { type: String }, challenges: [{ type: String }], depth: { type: Number } } }], ecpub: { type: String, min: 64, max: 66 }, ecprv: { type: String, min: 64, max: 64 }, policies: [{ type: String }], _lastAuditTimestamp: { type: Date, default: Date.now }, _isOwner: { type: Boolean, default: true } }); ObjectPointer.set('toObject', { transform: (doc, ret) =&gt; { delete ret._id; delete ret.__v; delete ret._lastAuditTimestamp; delete ret._isOwner; delete ret.ecprv; ret.id = doc._id; ret.shards = doc.shards.map(s =&gt; { return { size: s.size, hash: s.hash, service: s.service }; }); } }); ObjectPointer.virtual('percentDecayed').get(function() { let total = this.shards.length; let decayed = this.shards.filter(s =&gt; s.decayed).length; return decayed / total; }); /** * Returns a self encrypted blob version of the pointer * @returns {object} */ ObjectPointer.methods.toEncryptedBlob = function() { const password = utils.rmd160sha256(stringify(this.toObject())); const cipher = crypto.createCipher('aes256', password); let blob = Buffer.concat([ cipher.update(stringify(this.toObject()), 'utf8'), cipher.final() ]); const hash = utils.rmd160(blob); const magnet = `magnet:?xt=urn:orc:${hash.toString('hex')}` + `&amp;xs=${this.size}` + `&amp;dn=${this.name}` + `&amp;x.ecprv=${this.ecprv}` + `&amp;x.pword=${password.toString('hex')}`; return { blob, hash, magnet }; }; /** * Some arbitrary blob of data stored in the DHT * @constructor * @memberof Database * @param {object} properties * @param {string} properties.key - 160 bit hexidecimal key (hash of value) * @param {string} properties.value - Arbitrary value to store (base64) * @param {string} properties.publisher - Identity key of the author of entry * @param {number} properties.timestamp - Time the item was stored */ const NetworkBlob = new Schema({ key: { type: String, required: true, unique: true }, value: { type: String, required: true }, publisher: { type: String, required: true }, timestamp: { type: Date, required: true, default: Date.now } }); NetworkBlob.set('toObject', { transform: (doc, ret) =&gt; { delete ret._id; delete ret.__v; delete ret.key; } }); /** * Wraps a MongoDB connection and initializes models */ class Database extends EventEmitter { static get schemas() { return { PeerProfile, ShardContract, AuditReport, ObjectPointer, NetworkBlob }; } /** * @constructor * @param {string} connectionUri - Valid MongoDB URI string for connecting */ constructor(uri) { super(); this.connection = createConnection.call(mongoose, uri, { useMongoClient: true }); this.connection.on('error', (err) =&gt; this.emit('error', err)); this.connection.on('open', () =&gt; this.emit('open')); for (let name in Database.schemas) { this[name] = this.connection.model(name, Database.schemas[name]); } } } /** * Wraps the supplied model for a kad/levelup compatible interface */ class KadStorageAdapter { /** * @constructor * @param {object} databaseModel */ constructor(model, keyName = 'key') { this.model = model; this.keyName = keyName; } /** * Get item by key * @param {string} key - 160 hex key * @param {object} [options] - Stubbed for levelup compatibility * @param {function} callback */ get(key, options, callback) { /* istanbul ignore else */ if (typeof options === 'function') { callback = options; options = {}; } this.model.findOne({ [this.keyName]: key }, (err, doc) =&gt; { /* istanbul ignore if */ if (err) { return callback(err); } /* istanbul ignore if */ if (!doc) { return callback(new Error('Not found')); } callback(null, doc.toObject()); }); } /** * Put item by key * @param {string} key - 160 bit hex key (hash of value) * @param {object} value - Arbitrary base64 string * @param {object} [options] - Stubbed for levelup compatibility * @param {function} callback */ put(key, value, options, callback) { /* istanbul ignore else */ if (typeof options === 'function') { callback = options; options = {}; } this.model.findOneAndUpdate({ [this.keyName]: key }, value, { upsert: true }, callback); } /** * Delete item by key * @param {string} key - 160 bit hex key * @param {function} callback */ del(key, callback) { this.model.remove({ [this.keyName]: key }, callback); } /** * Returns a readable stream of all items * @returns {ReadableStream} */ createReadStream() { const rs = new ReadableStream({ read: () =&gt; null, objectMode: true }); const cursor = this.model.find({}).cursor(); cursor .on('data', (doc) =&gt; { rs.push({ key: doc.key, value: doc.toObject() }) }) .on('error', (err) =&gt; { /* istanbul ignore next */ rs.emit('error', err); }) .on('end', () =&gt; rs.push(null)); return rs; } } module.exports = Database; module.exports.KadStorageAdapter = KadStorageAdapter; × Search results Close "},"constants.js.html":{"id":"constants.js.html","title":"Source: constants.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: constants.js /** * @module orc/constants */ 'use strict'; module.exports = { /** * @constant {number} AUDIT_BYTES - Number of bytes for audit challenge */ AUDIT_BYTES: 32, /** * @constant {number} CLEAN_INTERVAL - Interval for reaping stale shards */ CLEAN_INTERVAL: 86400000, /** * @constant {number} CONSIGN_THRESHOLD - Threshold for consign time */ CONSIGN_THRESHOLD: 86400000, /** * @constant {number} TOKEN_EXPIRE - Reject data token after time */ TOKEN_EXPIRE: 1800000, /** * @constant {number }MAX_NODE_INDEX - Maximum node index */ MAX_NODE_INDEX: 0x7fffffff, /** * @constant {string} HD_KEY_DERIVATION_PATH - Key derivation path for HD key */ HD_KEY_DERIVATION_PATH: 'm/3000\\'/0\\'', /** * @constant {number} AUDIT_INTERVAL - Time interval for audit check */ AUDIT_INTERVAL: 10800000, /** * @constant {number} SCORE_INTERVAL - Time to score for reputation */ SCORE_INTERVAL: 259200000, /** * @constant {number} REAPER_GRACE - Grace period beyond score interval */ REAPER_GRACE: 172800000, /** * @constant {number} NUM_CHALLENGES - Total challenges to generate per object */ NUM_CHALLENGES: 12, /** * @constant {number} MAX_DECAY - Threshold for object decay for rebuilting */ MAX_DECAY: 0.15 }; × Search results Close "},"logger.js.html":{"id":"logger.js.html","title":"Source: logger.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: logger.js /** * @module orc/logger */ 'use strict'; const { Transform } = require('stream'); class IncomingMessage extends Transform { constructor(logger) { super({ objectMode: true }); this.logger = logger; } _transform(data, enc, callback) { let [rpc, ident] = data; if (!ident.payload.params[0] || !ident.payload.params[1]) { return callback(); } if (rpc.payload.method) { this.logger.info( `received ${rpc.payload.method} (${rpc.payload.id}) from ` + `${ident.payload.params[0]} ` + `(http://${ident.payload.params[1].hostname}:` + `${ident.payload.params[1].port})` ); } else { this.logger.info( `received response from ${ident.payload.params[0]} to ` + `${rpc.payload.id}` ); } callback(null, data); } } class OutgoingMessage extends Transform { constructor(logger) { super({ objectMode: true }); this.logger = logger; } _transform(data, enc, callback) { let [rpc,, recv] = data; if (!recv[0] || !recv[1]) { return callback(); } if (rpc.method) { this.logger.info( `sending ${rpc.method} (${rpc.id}) to ${recv[0]} ` + `(http://${recv[1].hostname}:${recv[1].port})` ); } else { this.logger.info( `sending response to ${recv[0]} for ${rpc.id}` ); } callback(null, data); } } module.exports = { IncomingMessage, OutgoingMessage }; × Search results Close "},"utils.js.html":{"id":"utils.js.html","title":"Source: utils.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: utils.js /** * @module orc/utils */ 'use strict'; const http = require('http'); const stream = require('stream'); const assert = require('assert'); const secp256k1 = require('secp256k1'); const HDKey = require('hdkey'); const constants = require('./constants'); const crypto = require('crypto'); const semver = require('semver'); const ip = require('ip'); /** * Returns the SHA-256 hash of the input * @param {string|buffer} input - Data to hash * @param {string} encoding - The encoding type of the data * @returns {buffer} */ module.exports.sha256 = function(input, encoding) { return crypto.createHash('sha256').update(input, encoding).digest(); }; /** * Returns the RIPEMD-160 hash of the input * @param {string|buffer} input - Data to hash * @param {string} encoding - The encoding type of the data * @returns {buffer} */ module.exports.rmd160 = function(input, encoding) { return crypto.createHash('rmd160').update(input, encoding).digest(); }; /** * Returns the RIPEMD-160 SHA-256 hash of this input * @param {string|buffer} input - Data to hash * @param {string} encoding - The encoding type of the data * @returns {buffer} */ module.exports.rmd160sha256 = function(input, encoding) { return module.exports.rmd160(module.exports.sha256(input, encoding)); }; /** * Returns the next power of two number * @param {number} number * @returns {number} */ module.exports.getNextPowerOfTwo = function(num) { return Math.pow(2, Math.ceil(Math.log(num) / Math.log(2))); }; /** * Returns a stringified URL from the supplied contact object * @param {array} contact * @param {string} contact.0 - Node identity key * @param {object} contact.1 * @param {string} contact.1.hostname * @param {string} contact.1.port * @param {string} contact.1.protocol * @returns {string} */ module.exports.getContactURL = function(contact) { const [, info] = contact; return `${info.protocol}//${info.hostname}:${info.port}`; }; /** * Returns whether or not the supplied semver tag is compatible * @param {string} version - The semver tag from the contact * @returns {boolean} */ module.exports.isCompatibleVersion = function(version) { const local = require('./version').protocol; const remote = version; const sameMajor = semver.major(local) === semver.major(remote); const diffs = ['prerelease', 'prepatch', 'preminor', 'premajor']; if (diffs.indexOf(semver.diff(remote, local)) !== -1) { return false; } else { return sameMajor; } }; /** * Determines if the supplied contact is valid * @param {array} contact - The contact information for a given peer * @param {boolean} loopback - Allows contacts that are localhost * @returns {boolean} */ module.exports.isValidContact = function(contact, loopback) { const [, info] = contact; const isValidAddr = ip.isV4Format(info.hostname) || ip.isV6Format(info.hostname) || ip.isPublic(info.hostname); const isValidPort = info.port &gt; 0; const isAllowedAddr = ip.isLoopback(info.hostname) ? !!loopback : true; return isValidPort &amp;&amp; isValidAddr &amp;&amp; isAllowedAddr; }; /** * Determines if a value is hexadecimal string * @param {*} a - The value to be tested * @returns {boolean} */ module.exports.isHexaString = function(a) { if (typeof a !== 'string') { return false; } return /^[0-9a-fA-F]+$/.test(a); }; /** * Checks if the supplied HD key is valid (base58 encoded) and proper length * @param {string} hdKey - The HD key in base 58 encoding * @returns {boolean} isValidHDKey */ module.exports.isValidHDNodeKey = function(hdKey) { return typeof hdKey === 'string' &amp;&amp; /^[1-9a-km-zA-HJ-NP-Z]{1,111}$/.test(hdKey); }; /** * Checks if the input is a non-hardened HD key index * @param {number} hdIndex - The HD key index * @returns {boolean} isValidHDKeyIndex */ module.exports.isValidNodeIndex = function(n) { return !Number.isNaN(n) &amp;&amp; (parseInt(n) === n) &amp;&amp; n &gt;= 0 &amp;&amp; n &lt;= constants.MAX_NODE_INDEX; }; /** * Returns a HD key object using corrent key derivation path using the * given seed * @param {buffer} seed64 - 64 byte seed for generating key * @returns {HDKey} */ module.exports.createComplexKeyFromSeed = function(seed64) { assert(Buffer.isBuffer(seed64), 'Seed must be a buffer'); assert(seed64.length === 64, 'Seed must be 64 bytes in length'); var hdKey = HDKey.fromMasterSeed(seed64).derive( constants.HD_KEY_DERIVATION_PATH ); return hdKey.privateExtendedKey; }; /** * Returns a request object for uploading a shard to a farmer * @param {array} farmer - Farmer contact object * @param {string} hash - The hash of the shard to upload * @param {string} token - The authorized transfer token * @param {Agent} [agent] * @returns {https.ClientRequest} */ module.exports.createShardUploader = function(farmer, hash, token, agent) { const [, contact] = farmer; function _createUploadStream() { return http.request({ method: 'POST', protocol: contact.protocol, hostname: contact.hostname, port: contact.port, path: `/shards/${hash}?token=${token}`, headers: { 'content-type': 'application/octet-stream' }, agent: agent }); } return new stream.Transform({ transform: function(chunk, encoding, callback) { /* istanbul ignore else */ if (!this._uploader) { this._uploader = _createUploadStream(); this._uploader.on('response', this.emit.bind(this, 'response')); this._uploader.on('error', (err) =&gt; { this.unpipe(); this.emit('error', err); }); } this._uploader.write(chunk, encoding, callback); }, flush: function(callback) { /* istanbul ignore else */ if (this._uploader) { this._uploader.end(); } callback(); } }); }; /** * Returns a request object for downloading a shard from a farmer * @param {array} farmer - Farmer contact object * @param {string} hash - The hash of the shard to upload * @param {string} token - The authorized transfer token * @param {Agent} [agent] * @returns {https.ClientRequest} */ module.exports.createShardDownloader = function(farmer, hash, token, agent) { const [, contact] = farmer; function _createDownloadStream() { return http.get({ protocol: contact.protocol, hostname: contact.hostname, port: contact.port, path: `/shards/${hash}?token=${token}`, headers: { 'content-type': 'application/octet-stream' }, agent: agent }); } return new stream.Readable({ read: function() { if (!this._downloader) { this._downloader = _createDownloadStream(); this._downloader.on('response', (res) =&gt; { res .on('data', this.push.bind(this)) .on('error', this.emit.bind(this, 'error')) .on('end', this.push.bind(this, null)); }) .on('error', this.emit.bind(this, 'error')); } } }); }; /** * Returns a cipher stream using aes256-cbc-sha256-hmac using a ECDH secret * derived from the given public and private keys * @param {buffer} publicKey - SECP256k1 public key bytes * @param {buffer} privateKey - SECP256k1 private key bytes * @returns {object} */ module.exports.createCipher = function(publicKey, privateKey) { const secret = secp256k1.ecdh(publicKey, privateKey); const cipher = crypto.createCipher('aes-256-cbc', secret); return cipher; }; /** * Returns a cipher stream using aes256-cbc-sha256-hmac using a ECDH secret * derived from the given public and private keys * @param {buffer} publicKey - SECP256k1 public key bytes * @param {buffer} privateKey - SECP256k1 private key bytes * @returns {object} */ module.exports.createDecipher = function(publicKey, privateKey) { const secret = secp256k1.ecdh(publicKey, privateKey); const decipher = crypto.createDecipher('aes-256-cbc', secret); return decipher; }; /** * Returns the appropriate shard size, number of shards, and number of parity * shards for RS encoding/decoding provided the total number of bytes of the * complete content * @param {number} n - Number of bytes in data * @returns {object} */ module.exports.getErasureParameters = function(n) { let size = 8 * (1024 * 1024); let params = { shards: 4, parity: 2, get length() { return n + params.padding; }, get size() { return params.length / params.shards; }, padding: 0 }; function accumulate() { if (n &gt; size &amp;&amp; params.shards !== 16 &amp;&amp; params.parity !== 8) { size = size * 8; params.shards = params.shards * 2; params.parity = params.parity * 2; while (!Number.isSafeInteger(params.size)) { params.padding++; } return accumulate(); } else { return params; } } return accumulate(); }; /** * Returns a readable stream version of the given buffer * @param {buffer} buffer * @returns {object} */ module.exports.bufferAsReadableStream = function(buffer) { return new stream.Readable({ read: function() { if (this._bufferDrained) { this.push(null); } else { this._bufferDrained = true; this.push(buffer); } } }); }; /** * Returns a dictionary of capacity information from contact flags * @param {array} flags * @returns {object} */ module.exports.getCapacityFromFlags = function(flags = []) { let capacity = { allocated: 0, available: 0 }; try { for (let [flag, value] of flags) { switch (flag) { case 'ALLOCATED': capacity.allocated = value; break; case 'AVAILABLE': capacity.available = value; break; default: continue; } } } catch (err) { return capacity; } return capacity; }; × Search results Close "},"version.js.html":{"id":"version.js.html","title":"Source: version.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: version.js /** * @module orc/version */ 'use strict'; var semver = require('semver'); var assert = require('assert'); var postfix = process.env.ORC_NETWORK ? `-${process.env.ORC_NETWORK}` : ''; module.exports = { /** * @constant {string} protocol - The supported protocol version */ protocol: '4.0.0' + postfix, /** * @constant {string} software - The current software version */ software: require('../package').version, /** * Returns human readable string of versions * @function * @returns {string} */ toString: function() { let { software, protocol } = module.exports; return `orc v${software} protocol v${protocol}`; } }; assert( semver.valid(module.exports.protocol), 'Invalid protocol version specified' ); × Search results Close "},"node.js.html":{"id":"node.js.html","title":"Source: node.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: node.js 'use strict'; const url = require('url'); const { createLogger } = require('bunyan'); const merge = require('merge'); const http = require('http'); const kad = require('kad'); const quasar = require('kad-quasar'); const spartacus = require('kad-spartacus'); const cas = require('kad-content'); const hashcash = require('kad-hashcash'); const constants = require('./constants'); const async = require('async'); const ms = require('ms'); const utils = require('./utils'); const version = require('./version'); const Rules = require('./rules'); const Server = require('./server'); const Transport = require('./transport'); const Database = require('./database'); /** * Extends Kademlia with Orc protocol rules * @license AGPL-3.0 */ class Node extends kad.KademliaNode { static get DEFAULTS() { return { logger: createLogger({ name: 'orcd' }), transport: new Transport(), privateExtendedKey: null, keyDerivationIndex: 1, flags: [] }; } /** * @constructor * @extends {KademliaNode} * @param {object} options * @param {string} options.privateExtendedKey - HD extended private key * @param {object} [options.logger] - Bunyan compatible logger * @param {Transport} [options.transport] * @param {Database} options.database * @param {Shards} options.shards * @param {number} [options.keyDerivationIndex] - HD derivation index */ constructor(options) { /* eslint max-statements: [2, 16] */ const opts = merge(Node.DEFAULTS, options, { storage: new Database.KadStorageAdapter(options.database.NetworkBlob) }); super(opts); this.flags = opts.flags; this.contact.agent = this.contact.agent || version.protocol; this.hashcash = this.plugin(hashcash({ methods: ['PUBLISH', 'STORE', 'CLAIM'], difficulty: 4 })); this.quasar = this.plugin(quasar); this.spartacus = this.plugin(spartacus( options.privateExtendedKey, options.keyDerivationIndex, constants.HD_KEY_DERIVATION_PATH )); this.cas = this.plugin(cas({ keyAlgorithm: 'rmd160', valueEncoding: 'base64' })); this.database = opts.database; this.shards = opts.shards; this.server = new Server({ database: this.database, shards: this.shards, identity: this.identity }); this.transport.on('identify', (req, res) =&gt; { this.logger.debug('responding to peer requested identification'); res.end(JSON.stringify([ this.identity.toString('hex'), this.contact ])); }); this.transport.on('download', (req, res) =&gt; { this.logger.debug('handling shard download request'); this.server.download(req, res) }); this.transport.on('upload', (req, res) =&gt; { this.logger.debug('handling shard upload request'); this.server.upload(req, res) }); this._bootstrap(); } /** * @private */ _bootstrap() { // Keep a record of the contacts we've seen this.router.events.on('add', (identity) =&gt; { let contact = this.router.getContactByNodeId(identity); let capacity = utils.getCapacityFromFlags(contact.flags); this.logger.debug(`updating peer profile ${identity}`); this.database.PeerProfile.findOneAndUpdate( { identity: identity.toString('hex') }, { identity: identity.toString('hex'), contact, updated: Date.now(), capacity }, { upsert: true }, () =&gt; null ); }); } /** * Returns a list of bootstrap nodes from local profiles * @returns {string[]} urls */ getBootstrapCandidates() { return new Promise((resolve, reject) =&gt; { this.database.PeerProfile.find({ updated: { $gt: Date.now() - ms('48HR') }, identity: { $ne: this.identity.toString('hex') } }).sort({ updated: -1 }).limit(10).exec((err, profiles) =&gt; { if (err) { this.logger.warn(err.message); return reject(err); } resolve(profiles.map((p) =&gt; p.toString())); }); }); } /** * Performs any periodic updates to the contact flags we include * in every message * @param {boolean} soft - Don't do iterativeFindNode on update */ updateFlags(soft) { return new Promise((resolve, reject) =&gt; { this.shards.size((err, data) =&gt; { /* istanbul ignore if */ if (err) { this.logger.warn('failed to measure capacity'); return reject(err); } this.contact.flags = this.flags.concat([ ['ALLOCATED', data.allocated], ['AVAILABLE', data.available] ]); // Update our own peer profile this.database.PeerProfile.findOneAndUpdate( { identity: this.identity.toString('hex') }, { contact: this.contact, updated: Date.now(), capacity: utils.getCapacityFromFlags(this.contact) }, { upsert: true } ); if (soft) { return resolve(); } this.iterativeFindNode(this.identity.toString('hex'), () =&gt; resolve()); }); }); } /** * Scans the contract database for stale contracts to reap */ reapExpiredShards() { // TODO: Checks for contracts held that have not been audited within // TODO: the last N blocks in the chain and reaps them } /** * Adds the kademlia rule handlers before calling super#listen() */ listen() { let handlers = new Rules(this); this.use(handlers.validate.bind(handlers)); this.use('AUDIT', handlers.audit.bind(handlers)); this.use('CONSIGN', handlers.consign.bind(handlers)); this.use('RETRIEVE', handlers.retrieve.bind(handlers)); this.use('RENEW', handlers.renew.bind(handlers)); this.use('CLAIM', handlers.claim.bind(handlers)); // TODO: Add chain messages super.listen(...arguments); } /** * Sends a GET request to the URI and parses the result as a valid * contact object with identity * @param {string} url - The URL of the node * @param {Node~identifyServiceCallback} callback */ identifyService(uri, callback) { const options = merge(url.parse(uri), { agent: this.onion.createClearAgent(), method: 'GET' }); const req = http.request(options, (res) =&gt; { let body = ''; res.on('error', callback); res.on('data', (data) =&gt; body += data.toString()); res.on('end', () =&gt; { if (res.statusCode !== 200) { callback(new Error(body)); } else { try { callback(null, JSON.parse(body)); } catch (err) { callback(new Error('Failed to parse identity')); } } }); }); req.on('error', callback); req.end(); } /** * @callback Node~identifyServiceCallback * @param {error|null} error * @param {array} contact */ /** * Requests authorization tokens to pull file shard(s) from another node * @param {array} peer * @param {string} peer.0 - Identity key string * @param {string|object} peer.1 - Address data for contact * @param {string[]} hashes - Hashes of the shards to pull * @param {Node~authorizeRetrievalCallback} callback */ authorizeRetrieval(peer, hashes, callback) { this.send('RETRIEVE', hashes, peer, callback); } /** * @callback Node~authorizeRetrievalCallback * @param {error|null} error * @param {string[]} retrievalTokens */ /** * Requests authorization tokens to push file shard(s) to another node * @param {array} peer * @param {string} peer.0 - Identity key string * @param {string|object} peer.1 - Address data for contact * @param {string[]} hashes - Hashes of the shards to push * @param {Node~authorizeConsignmentCallback} callback */ authorizeConsignment(peer, hashes, callback) { this.send('CONSIGN', hashes, peer, callback); } /** * @callback Node~authorizeConsignmentCallback * @param {error|null} error * @param {string[]} consignmentTokens */ /** * Requests the source node to MIRROR a shard to the supplied destination * @param {array} source * @param {string} source.0 - Identity key string * @param {string|object} source.1 - Address data for contact * @param {object} target * @param {array} target.destination - * @param {string} target.destination.0 - Identity key string * @param {string|object} target.destination.1 - Address data for contact * @param {string} target.hash - Hash of the shard to mirror * @param {string} target.token - Authorization token to PUSH shard * @param {Node~createShardMirrorCallback} callback */ createShardMirror(source, target, callback) { this.send('MIRROR', [target.hash, target.token, target.destination], source, callback); } /** * @callback Node~createShardMirrorCallback * @param {object|null} error */ /** * Sends the series of hash/challenge pairs to the remote node to request * proof-of-storage * @param {array} peer * @param {string} peer.0 - Identity key string * @param {string|object} peer.1 - Address data for contact * @param {object[]} audits * @param {string} audits.hash - Hash of the shard to prove * @param {string} audits.challenge - Challenge string to prepend to shard * @param {Node~auditRemoteShardsCallback} callback */ auditRemoteShards(peer, audits, callback) { this.send('AUDIT', audits, peer, callback); } /** * @callback Node~auditRemoteShardsCallback * @param {object|null} error * @param {object[]} proofs * @param {string} proofs.hash - Hash of the shard for corresponding proof * @param {string} proofs.proof - {@tutorial compact-merkle-proof} */ /** * Requests that the target peer update their local version of the given * contract. Used to extend storage time or terminate storage. Peer will * respond with an error or their updated, signed record of the renewal. * @param {array} peer * @param {string} peer.0 - Identity key string * @param {object} peer.1 - Address data for contact * @param {object} contract - The completed shard descriptor contract * @param {Node~requestContractRenewalCallback} callback */ requestContractRenewal(peer, descriptor, callback) { this.send('RENEW', [descriptor], peer, (err, result) =&gt; { if (err) { return callback(err); } const contract = new this.database.ShardContract(result[0]); if (!(!contract.validateSync() &amp;&amp; contract.verify('owner'))) { return callback(new Error( 'Peer replied with invalid or incomplete contract' )); } this.database.ShardContract.findOneAndUpdate({ shardHash: descriptor.shardHash }, result[0], (err) =&gt; callback(err, contract)); }); } /** * @callback Node~requestContractRenewalCallback * @param {error|null} error * @param {object} contract - See {@tutorial storage-contracts} */ /** * Claims capacity from a farming node, given a valid contract * @param {array} peer * @param {string} peer.0 - Identity key string * @param {string|object} peer.1 - Address data for contact * @param {object} descriptor - Contract descriptor * @param {Node~claimProviderCapacityCallback} callback */ claimProviderCapacity(peer, descriptor, callback) { this.send('CLAIM', [descriptor], peer, callback); } /** * @callback Node~claimProviderCapacityCallback * @param {error|null} error * @param {array} result * @param {object} result.0 - Completed contract result * @param {string} result.1 - Consignment token */ /** * Publishes the supplied audit reports to nearest neighbors * @param {array[]} report * @param {Node~reportAuditResultsCallback} callback */ reportAuditResults(report, callback) { const peers = this.router.getClosestContactsToKey( this.identity, kad.constants.ALPHA ); async.each(peers, (peer, done) =&gt; { this.send('REPORT', report, peer, done); }, callback); } /** * Make sure incompatible nodes don't make it into our routing table * @private */ _updateContact(identity, contact) { try { if (!utils.isCompatibleVersion(contact.agent)) { return; } } catch (err) { return; } super._updateContact(...arguments); } } module.exports = Node; × Search results Close "},"proof.js.html":{"id":"proof.js.html","title":"Source: proof.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: proof.js 'use strict'; const { Transform: TransformStream } = require('stream'); const assert = require('assert'); const MerkleTree = require('mtree'); const crypto = require('crypto'); const utils = require('./utils'); /** * Provides interface for proving possession of a file for an * {@link AuditStream} */ class Proof extends TransformStream { /** * Verifies the proof given the merkle root and tree depth * @static * @memberof Proof * @param {*} proof - Compact proof result * @param {string} root - Merkle tree root from audit leaves * @param {number} depth - Depth of the merkle tree * @returns {string[]} */ static verify(proof, root, depth) { function _getChallengeResponse(tuple) { let data = tuple || proof; if (data.length === 1) { return utils.rmd160sha256(data[0], 'hex'); } if (Array.isArray(data[0])) { return _getChallengeResponse(data[0]); } else if (Array.isArray(data[1])) { return _getChallengeResponse(data[1]); } else { return Buffer.alloc(20, 0).toString('hex'); } } function _collapse(proof, leaf, depth) { if (depth === 0) { assert(proof.length === 1, 'Invalid proof structure'); const proofhash = utils.rmd160sha256(proof[0], 'hex'); assert(Buffer.compare(proofhash, leaf) === 0, 'Invalid proof value'); return leaf; } let hashL, hashR; if (Array.isArray(proof[0])) { hashL = _collapse(proof[0], leaf, depth - 1); } else { hashL = proof[0] || Buffer.alloc(20, 0).toString('hex'); } if (Array.isArray(proof[1])) { hashR = _collapse(proof[1], leaf, depth - 1); } else { hashR = proof[1] || Buffer.alloc(20, 0).toString('hex'); } return utils.rmd160sha256(Buffer.concat([ Buffer.from(hashL, 'hex'), Buffer.from(hashR, 'hex') ])); } return [ proof &amp;&amp; proof.length ? _collapse(proof, _getChallengeResponse(), depth - 1) : Buffer.alloc(20, 0), root ]; } /** * @constructor * @param {string[]} merkleLeaves - Bottom leaves of the audit merkle tree * @param {string|buffer} hexChallenge - The challenge data in hex to prepend * to shard */ constructor(leaves, challenge) { super({ objectMode: true }); assert(Array.isArray(leaves), 'Merkle leaves must be an array'); assert.ok(challenge, 'Invalid challenge supplied'); this._tree = new MerkleTree(this._generateLeaves(leaves), utils.rmd160sha256); if (!Buffer.isBuffer(challenge)) { this._challenge = Buffer.from(challenge, 'hex'); } else { this._challenge = challenge; } this._hasher = crypto.createHash('sha256').update(this._challenge); this._proof = null; } /** * Returns the generated proof structure * @return {array} */ getProofResult() { assert(Array.isArray(this._proof), 'Proof generation is not complete'); return this._proof; } /** * Handles writing the shard data to the proof stream * @private */ _transform(chunk, encoding, next) { this._hasher.update(chunk, encoding); next(); } /** * Generates the proof from the read data * @private */ _flush(done) { try { this._generateProof(); } catch (err) { return done(err); } this.push(this.getProofResult()); done(); } /** * Returns the index of the associated audit leaf * @private */ _findMatchIndex(leaves, leaf) { let challengenum = -1; for (let l = 0; l &lt; leaves.length; l++) { if (Buffer.compare(leaves[l], leaf) === 0) { challengenum = l; break; } } return challengenum; } /** * Calculate audit response * @private * @param {string} challenge - Challenge string sent by auditor * @returns {string[]} result - Challenge response */ _generateProof() { const response = utils.rmd160(this._hasher.digest()); const leaves = this._tree.level(this._tree.levels() - 1); const leaf = utils.rmd160sha256(response); let challengenum = this._findMatchIndex(leaves, leaf); let branches = [response.toString('hex')]; assert(challengenum !== -1, 'Failed to generate proof'); for (let i = (this._tree.levels() - 1); i &gt; 0; i--) { let level = this._tree.level(i); if (challengenum % 2 === 0) { branches = [branches, level[challengenum + 1].toString('hex')]; } else { branches = [level[challengenum - 1].toString('hex'), branches]; } challengenum = Math.floor(challengenum / 2); } this._proof = branches; } /** * Generates the bottom leaves of the tree to the next power of two * @private * @param {string[]} leaves */ _generateLeaves(leaves) { const numEmpty = utils.getNextPowerOfTwo(leaves.length) - leaves.length; const emptyLeaves = []; for (let i = 0; i &lt; numEmpty; i++) { emptyLeaves.push(utils.rmd160sha256('')); } return leaves.map((i) =&gt; Buffer.from(i, 'hex')).concat(emptyLeaves); } } module.exports = Proof; × Search results Close "},"rules.js.html":{"id":"rules.js.html","title":"Source: rules.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: rules.js 'use strict'; const { randomBytes } = require('crypto'); const assert = require('assert'); const async = require('async'); const utils = require('./utils'); const ProofStream = require('./proof'); /** * Represents Orc protocol handlers */ class Rules { /** * Constructs a Orc rules instance in the context of a Orc node * @constructor * @param {Node} node */ constructor(node) { this.node = node; } /** * Validates all incoming RPC messages * @param {object} request * @param {object} response */ validate(request, response, next) { try { assert(utils.isCompatibleVersion(request.contact[1].agent), `Unsupported protocol version ${request.contact[1].agent}`); } catch (err) { return next(err); } return next(); } /** * Upon receipt of a AUDIT message, the node must look up the contract that * is associated with each hash-challenge pair in the payload, prepend the * challenge to the shard data, and caclulate the resulting hash, formatted * as a compact proof. See {@tutorial compact-proofs}. * @param {object} request * @param {object} response */ audit(request, response, next) { const audits = request.params; if (!Array.isArray(audits)) { return next(new Error('Invalid audit batch supplied')); } async.mapSeries(audits, ({ hash, challenge }, done) =&gt; { this.node.database.ShardContract.findOne({ shardHash: hash }, (err, contract) =&gt; { if (err || !contract) { return done(null, { hash, proof: [] }); } if (!contract.checkAccessPolicy(request.contact).includes('AUDIT')) { return next(new Error('Not authorized')); } if (!challenge) { return next(new Error('Invalid challenge supplied')); } const auditLeaves = contract.auditLeaves; const proofStream = new ProofStream(auditLeaves, challenge); proofStream.on('error', () =&gt; { proofStream.removeAllListeners('finish'); done(null, { hash, proof: [] }); }); proofStream.on('finish', () =&gt; { contract._lastAuditTimestamp = Date.now(); proofStream.removeAllListeners('error'); contract.save(() =&gt; { done(null, { hash, proof: proofStream.getProofResult() }); }); }); this.node.shards.createReadStream(hash, (err, shardStream) =&gt; { if (err) { return done(null, { hash, proof: [] }); } shardStream.pipe(proofStream); }); }); }, (err, proofs) =&gt; response.send(proofs)); } /** * Upon receipt of a CONSIGN message, the node must verify that it has a * valid storage allocation and contract for the supplied hash and identity * of the originator. If so, it must generate an authorization token which * will be checked by the shard server before accepting the transfer of the * associated shard. * @param {object} request * @param {object} response */ consign(request, response, next) { const [hash] = request.params; const { contact } = request; this.node.database.ShardContract.findOne({ shardHash: hash }, (err, contract) =&gt; { if (err || !contract) { return next(err || new Error('Contract not found')); } if (!contract.checkAccessPolicy(request.contact).includes('CONSIGN')) { return next(new Error('Not authorized')); } const token = randomBytes(32).toString('hex'); this.node.server.accept(token, hash, contact); response.send([token]); }); } /** * Upon receipt of a RETRIEVE message, the node must verify that it is in * possession of the shard on behalf of the identity of the originator. * If so, it must generate an authorization token which will be checked by * the shard server before accepting the transfer of the associated shard. * @param {object} request * @param {object} response */ retrieve(request, response, next) { const [hash] = request.params; const { contact } = request; this.node.database.ShardContract.findOne({ shardHash: hash }, (err, contract) =&gt; { if (err || !contract) { return next(err || new Error('Contract not found')); } const token = randomBytes(32).toString('hex'); this.node.shards.exists(hash, (err, exists) =&gt; { if (err || !exists) { return next(err || new Error('Shard not found')); } this.node.server.accept(token, hash, contact); response.send([token]); }); }); } /** * Upon receipt of a RENEW message, the recipient farmer must extend or * terminate it's contract based on the new terms supplied by the renter. * If the renewal descriptor is valid and complete, the farmer must store * the updated version after signing and respond back to the originator * with the version containing the updated signature. * @param {object} request * @param {object} response */ renew(request, response, next) { const [descriptor] = request.params; const renewal = new this.node.database.ShardContract(descriptor); const hash = renewal.shardHash; if (!(!renewal.validateSync() &amp;&amp; renewal.verify('owner'))) { return next(new Error('Descriptor is invalid or incomplete')); } this.node.database.ShardContract.findOne({ shardHash: hash }, (err, contract) =&gt; { if (err || !contract) { return next(err || new Error('Contract not found')); } const allowed = [ 'ownerIdentity', 'ownerParentKey', 'ownerIndex', 'auditLeaves', 'accessPolicies' ]; const difference = this.node.database.ShardContract.diff( contract, renewal ); for (let prop of difference.filter(p =&gt; !p.includes('Signature'))) { if (!allowed.includes(prop)) { return next(new Error(`Rejecting renewal of ${prop}`)); } } renewal.sign('provider', this.node.spartacus.privateKey); renewal.save((err) =&gt; { if (err) { return next(err); } response.send([renewal.toObject()]); }); }); } /** * Upon receipt of an `CLAIM` message, nodes must validate the descriptor, * then ensure that there is enough available space for the shard. If both * checks succeed, then the descriptor is signed and returned along with a * consignment token so the initiating renter can immediately upload the * data. These messages are generally sent based on information collected * when subscribed to farmer capacity publications. * @param {object} request * @param {object} response */ claim(request, response, next) { const [descriptor] = request.params; const contract = new this.node.database.ShardContract(descriptor); const hash = contract.shardHash; if (!contract.verify('owner')) { return next(new Error('Invalid shard descriptor')); } this.node.shards.size((err, result) =&gt; { if (err || (result.available &lt; contract.shardSize)) { return next(new Error('Not enough capacity available')); } contract.fundingDestination = null; contract.providerIdentity = this.node.identity.toString('hex'); contract.providerParentKey = this.node.contact.xpub; contract.providerIndex = this.node.contact.index; contract.sign('provider', this.node.spartacus.privateKey); if (contract.validateSync()) { return next(new Error('Invalid shard descriptor')); } contract.save((err) =&gt; { if (err) { return next(err); } const token = randomBytes(32).toString('hex'); this.node.server.accept(token, hash, request.contact); response.send([contract.toObject(), token]); }); }); } } module.exports = Rules; × Search results Close "},"server.js.html":{"id":"server.js.html","title":"Source: server.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: server.js 'use strict'; const merge = require('merge'); const async = require('async'); const assert = require('assert'); const { EventEmitter } = require('events'); const crypto = require('crypto'); const utils = require('./utils'); /** * Creates a shard server for sending and receiving consigned file shards */ class Server extends EventEmitter { static get DEFAULTS() { return { tokenTtl: 1800000 }; }; /** * @constructor * @license AGPL-3.0 * @param {object} options * @param {string} options.identity - Node identity key * @param {Database} options.database * @param {Shards} options.shards * @param {number} [options.tokenTtl=1800000] - Expire unused token */ constructor(options) { super(); options = merge(Server.DEFAULTS, options); this.identity = options.identity; this.shards = options.shards; this.database = options.database; this._allowed = new Map(); this._ttl = options.tokenTtl; setInterval(() =&gt; this._reapExpiredTokens(), this._ttl); } /** * Triggered when a shard has finished uploading to this instance * @event Server#shardUploaded * @param {string} hash - The hash associated with the upload */ /** * Triggered when a shard has finished downloading from this instance * @event Server#shardDownloaded * @param {string} hash - The hash associated with the download */ /** * Triggered when a error occurs * @event Server#error * @param {error} error */ /** * Begin accepting data for the given file hash and token * @param {string} token - The authorization token created for transfer * @param {string} filehash - The shard hash to allow for the token * @param {array} contact - Contact that negotiated the token */ accept(token, filehash, contact) { assert(typeof token === 'string', 'Invalid token supplied'); assert(typeof filehash === 'string', 'Invalid filehash supplied'); this._allowed.set(token, { hash: filehash, contact: contact, expires: Date.now() + this._ttl }); } /** * Stop accepting data for the given token * @param {string} token - The authorization token created for transfer */ reject(token) { assert(typeof token === 'string', 'Invalid token supplied'); this._allowed.delete(token); } /** * Validates the given token * @param {string} token * @param {string} hash * @returns {object} */ authorize(token, hash) { assert.ok(token, 'You did not supply a token'); assert.ok(this._allowed.has(token), 'The token is not accepted'); assert.ok(hash, 'You did not supply the data hash'); assert(this._allowed.get(token).expires &gt; Date.now(), 'Token expired'); assert(this._allowed.get(token).hash === hash, 'Token not valid'); return this._allowed.get(token); } /** * Receives the data stream and writes it to storage * @param {http.IncomingMessage} req * @param {http.ServerResponse} req */ upload(req, res) { const hasher = crypto.createHash('sha256'); const { hash } = merge({}, this._allowed.get(req.query.token)); function respond(err, statusCode) { res.statusCode = statusCode; res.end(err ? err.message : ''); } let shardSize = 0; let receivedBytes = 0; async.waterfall([ (next) =&gt; { try { this.authorize(req.query.token, req.params.hash); } catch (err) { return next(err, 401); } next(); }, (next) =&gt; { this.database.ShardContract.findOne({ shardHash: hash }, (err, contract) =&gt; { if (err || !contract) { return next(err || new Error('Not found'), 404); } shardSize = contract.shardSize; this.shards.createWriteStream(hash, (err, writeStream) =&gt; { if (err) { return next(err, 500); } next(null, writeStream, contract); }); }); }, (writeStream, contract, next) =&gt; { req.on('data', (chunk) =&gt; { receivedBytes += chunk.length; hasher.update(chunk); writeStream.write(chunk); if (receivedBytes &gt; shardSize) { this.shards.unlink(hash, () =&gt; null); next(new Error('Shard exceeds size defined in contract'), 400); } }); req.on('end', () =&gt; { if (utils.rmd160(hasher.digest()).toString('hex') !== hash) { this.shards.unlink(hash, () =&gt; null); return next(new Error('Hash does not match contract'), 400); } writeStream.end(); this.reject(req.query.token); this.emit('shardUploaded', contract); next(null, 200); }); } ], respond); } /** * Pumps the data through to the client * @param {http.IncomingMessage} req * @param {http.ServerResponse} res */ download(req, res) { function respond(err, statusCode) { res.statusCode = statusCode; res.end(err.message); } async.waterfall([ (next) =&gt; { try { this.authorize(req.query.token, req.params.hash); } catch (err) { return next(err, 401); } next(); }, (next) =&gt; { const { hash } = this._allowed.get(req.query.token); this.shards.createReadStream(hash, (err, readStream) =&gt; { if (err) { return next(err, 404); } this.database.ShardContract.update({ shardHash: hash }, { $set: { _lastAccessTimestamp: Date.now() } }, () =&gt; { next(null, readStream, hash); }); }); }, (readStream, hash) =&gt; { res.setHeader('content-type', 'application/octet-stream'); readStream .on('error', (/* err */) =&gt; res.end()) .on('end', () =&gt; { this.emit('shardDownloaded', hash); this.reject(req.query.token); }) .pipe(res); } ], respond); } /** * Enumerates the authorized list and rejects expired * @private */ _reapExpiredTokens() { let now = Date.now(); for (let [token] of this._allowed) { if (this._allowed.get(token).expires &lt; now) { this.reject(token); } } } } module.exports = Server; × Search results Close "},"shards.js.html":{"id":"shards.js.html","title":"Source: shards.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: shards.js 'use strict'; const merge = require('merge'); const assert = require('assert'); const fs = require('fs'); const du = require('du'); const path = require('path'); /** * Convenience wrapper for storing shards scoped to a directory */ class Shards { static get DEFAULTS() { return { maxSpaceAllocated: 0 }; } /** * @constructor * @param {string} directory - Directory path to shard storage */ constructor(directory, options) { assert.ok(directory, 'Invalid directory supplied'); assert(fs.existsSync(directory), 'Supplied directory does not exist'); this.directory = directory; this.options = merge(Shards.DEFAULTS, options); } /** * Wraps read stream with error handling/callback * @param {string} key - The file key or hash * @param {Shards~createReadStreamCallback} callback */ createReadStream(key, callback) { let rs = null; try { rs = fs.createReadStream(path.join(this.directory, key)); } catch (err) { return callback(err); } rs.once('error', (err) =&gt; callback(err)); rs.once('readable', () =&gt; callback(null, rs)); } /** * @callback Shards~createReadStreamCallback * @param {error|null} error * @param {object} stream */ /** * Wraps write stream with error handling/callback * @param {string} key - The file key or hash * @param {Shards~createWriteStreamCallback} callback */ createWriteStream(key, callback) { let ws = null; try { ws = fs.createWriteStream(path.join(this.directory, key)); } catch (err) { return callback(err); } callback(null, ws); } /** * @callback Shards~createWriteStreamCallback * @param {error|null} error * @param {object} stream */ /** * Unlink the shard from the file system * @param {string} key * @param {Shards~unlinkCallback} callback */ unlink(key, callback) { fs.unlink(path.join(this.directory, key), callback); } /** * @callback Shards~unlinkCallback * @param {error|null} error */ /** * Check if the shard exists * @param {string} key * @param {Shards~existsCallback} callback */ exists(key, callback) { callback(null, fs.existsSync(path.join(this.directory, key))); } /** * @callback Shards~existsCallback * @param {error|null} error * @param {boolean} exists */ /** * Get used space and remaining allocation * @param {Shards~sizeCallback} callback */ size(callback) { du(this.directory, (err, used) =&gt; { if (err) { return callback(err); } const allocated = this.options.maxSpaceAllocated; callback(null, { allocated, available: used &gt;= allocated ? 0 : allocated - used }); }); } /** * @callback Shards~sizeCallback * @param {error|null} error * @param {object} size */ } module.exports = Shards; × Search results Close "},"transport.js.html":{"id":"transport.js.html","title":"Source: transport.js","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Source: transport.js 'use strict'; const url = require('url'); const merge = require('merge'); const connect = require('connect'); const { HTTPTransport } = require('kad'); const { Agent } = require('http'); /** * Represents the ORC-specific HTTP transport */ class Transport extends HTTPTransport { /** * Emitted when a download request is received * @event Transport#download * @param {object} request * @param {object} response */ /** * Emitted when a upload request is received * @event Transport#upload * @param {object} request * @param {object} response */ /** * Contructs a Orc transport adapter * @constructor */ constructor(options) { super(options); } /** * Make sure we explicity set the keepAlive options on requests * @private */ _createRequest(options) { const request = super._createRequest(merge({ agent: new Agent({ keepAlive: true, keepAliveMsecs: 25000 }), path: '/rpc/' }, options)); request.setNoDelay(true); return request; } /** * Disable nagle algorithm on connections * @private */ _createServer(options) { const server = super._createServer(options); server.on('connection', (sock) =&gt; sock.setNoDelay(true)); return server; } /** * Handles requests by sending through middleware stack * @private */ _handle() { const middleware = connect(); middleware.use(Transport.CORS); middleware.use('/', (req, res, next) =&gt; { return req.url !== '/' ? next() : this.emit('identify', req, res); }); middleware.use('/rpc/', super._handle.bind(this)); middleware.use('/shards/', this._shards.bind(this)); middleware(...arguments); } /** * Handle routing request to shard server * @private */ _shards(req, res) { const urlobj = url.parse(req.originalUrl, true); const [, hash] = urlobj.pathname.split('/shards/'); req.query = urlobj.query; req.params = { hash }; if (req.method === 'POST') { this.emit('upload', req, res); } else if (req.method === 'GET') { this.emit('download', req, res); } else { res.statusCode = 405; res.end(); } } /** * Applies cross origin headers to responses * @static * @memberof Transport * @private */ static get CORS() { return function(req, res, next) { res.setHeader('access-control-allow-origin', '*'); res.setHeader('access-control-allow-methods', '*'); res.setHeader('access-control-allow-headers', '*'); if (req.method === 'OPTIONS') { res.statusCode = 200; res.end(); } else { next(); } } } } module.exports = Transport; × Search results Close "},"modules.list.html":{"id":"modules.list.html","title":"Modules","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Modules Classes Audit Bridge Database AuditReport NetworkBlob ObjectPointer PeerProfile ShardContract KadStorageAdapter Node Proof Rules Server Shards Transport Events error Triggered when a error occurs Parameters: Name Type Description error error Source: server.js shardDownloaded Triggered when a shard has finished downloading from this instance Parameters: Name Type Description hash string The hash associated with the download Source: server.js shardUploaded Triggered when a shard has finished uploading to this instance Parameters: Name Type Description hash string The hash associated with the upload Source: server.js download Emitted when a download request is received Parameters: Name Type Description request object response object Source: transport.js upload Emitted when a upload request is received Parameters: Name Type Description request object response object Source: transport.js × Search results Close "},"classes.list.html":{"id":"classes.list.html","title":"Classes","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Classes Classes Audit Bridge Database AuditReport NetworkBlob ObjectPointer PeerProfile ShardContract KadStorageAdapter Node Proof Rules Server Shards Transport Events error Triggered when a error occurs Parameters: Name Type Description error error Source: server.js shardDownloaded Triggered when a shard has finished downloading from this instance Parameters: Name Type Description hash string The hash associated with the download Source: server.js shardUploaded Triggered when a shard has finished uploading to this instance Parameters: Name Type Description hash string The hash associated with the upload Source: server.js download Emitted when a download request is received Parameters: Name Type Description request object response object Source: transport.js upload Emitted when a upload request is received Parameters: Name Type Description request object response object Source: transport.js × Search results Close "},"tutorials.list.html":{"id":"tutorials.list.html","title":"Tutorials","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Tutorials Classes Audit Bridge Database AuditReport NetworkBlob ObjectPointer PeerProfile ShardContract KadStorageAdapter Node Proof Rules Server Shards Transport Events error Triggered when a error occurs Parameters: Name Type Description error error Source: server.js shardDownloaded Triggered when a shard has finished downloading from this instance Parameters: Name Type Description hash string The hash associated with the download Source: server.js shardUploaded Triggered when a shard has finished uploading to this instance Parameters: Name Type Description hash string The hash associated with the upload Source: server.js download Emitted when a download request is received Parameters: Name Type Description request object response object Source: transport.js upload Emitted when a upload request is received Parameters: Name Type Description request object response object Source: transport.js × Search results Close "},"index.html":{"id":"index.html","title":"Index","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation The Onion Routed Cloud. ORC is a distributed anonymous cloud storage network owned and operated by all of us. Join the discussion in #orc on our community chat! | | | | Warning! ORC is alpha software and is still a highly experimental test network! Be smart, keep backups, and stay safe out there! InstallationPull the image from Docker Hub. docker pull orcproject/orcCreate a data directory on the host. mkdir ~/.config/orcdIf you are running ORC for the first time, mount the data directory and run it normally. docker run --volume ~/.config/orcd:/root/.config/orcd orcproject/orcThis will generate a fresh configuration and setup the data directory. Modify the created configuration at ~/.config/orcd/config as desired (see the Configuration Guide) and send SIGINT to the process (Ctrl+C). If you want to provide storage capacity to the network, be sure to set your desired allocation for ShardStorageMaxAllocation. Once you are finished, run the ORC container again, but expose the API to the host, mount the data directory, allocate a pseudo TTY, detach the process, and tell docker to keep it running (even starting automatically on system boot). docker run \\ --publish 127.0.0.1:9089:9089 \\ --volume ~/.config/orcd:/root/.config/orcd \\ --tty --detach orcproject/orcOnce the container has started, you can use use the guide for Using the REST API to interact with it! You can watch your logs with tail -f ~/.config/orcd/orcd.log. See the docker run documentation for more information. If you prefer to install ORC manually, see the guide for Manual Installation. Once installed, simply run orcd with an optional configuration file using the --config &lt;path/to/config&gt; option. Automatic Security UpdatesWhen running the ORC server installation with Docker, you can configure your node to periodically check for updates and automatically download the latest image and restart your node to make sure you are always running the latest stable release. Since you already have Docker installed, pull the image for Watchtower and run it. docker pull v2tec/watchtower docker run -d --name watchtower -v /var/run/docker.sock:/var/run/docker.sock v2tec/watchtowerNow, Watchtower will check for the latest stable images for running containers and automatically update them. DevelopmentTo hack on the ORC project, clone this repository and use Docker Compose: git clone https://github.com/orcproject/orc cd orc docker-compose up --force-recreate --buildThis will volume mount the the appropriate directories for development, and then boots up a complete sandboxed ORC network, including a complete sandboxed Tor network and once bootstrapped, binds port 9089 to the host for full end-to-end testing. The development container does not persist state between runs. Note that stable releases are tagged and the master branch may contain unstable or bleeding-edge code. Happy hacking! Resources Documentation Specification LicenseORC - Distributed Anonymous CloudCopyright (C) 2017 Counterpoint Hackerspace, Ltd.Copyright (C) 2017 Gordon Hall This program is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License for more details. You should have received a copy of the GNU Affero General Public License along with this program. If not, see http://www.gnu.org/licenses/. × Search results Close "},"Audit.html":{"id":"Audit.html","title":"Class: Audit","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: Audit Audit Represents a streaming audit challenge generator new Audit(audits) Parameters: Name Type Description audits number Total number of challenges to generate Source: audit.js Methods &lt;static&gt; fromRecords(challenges, tree) Returns a new instance from the predefined challenges and tree Parameters: Name Type Description challenges array The precomputed challenges tree array The bottom leaves of the existing merkle tree Source: audit.js Returns: Type Audit getPrivateRecord() Returns the challenges, the tree depth, and merkle root Source: audit.js Returns: challenge - Private audit record with challenges Type Object getPublicRecord() Returns the bottom leaves of the merkle tree for sending to farmer Source: audit.js Returns: leaves - Bottom merkle leaves of audit tree Type Array × Search results Close "},"Bridge.html":{"id":"Bridge.html","title":"Class: Bridge","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: Bridge Bridge Represents a local HTTP(s) server that abstracts the upload and download of files away to a simple request. Files are encrypted to the given public key, split into shards for erasure codes. Prepped for distribution and queued for storing in the network. Bridge exposes a simple API for getting status of transfers and previously stored objects. GET / (List objects as JSON - or serve Web GUI) GET /{hash} (Download object) DELETE /{hash} (Delete object) POST / (Upload object - Multipart) If auth is enabled, then the websocket event stream expects: ?auth={base64(user:pass)} as the query string new Bridge(node, options) Parameters: Name Type Description node Node options object Source: bridge.js Methods audit(callback, callback) Periodically call this to scan the object store for shards that need to be audited Parameters: Name Type Description callback callback function Source: bridge.js authenticate(request, response, next) Handles request authentication if defined Parameters: Name Type Description request object response object next function Source: bridge.js destroyObject(request, response, next) Ends contracts with farmers for the object parts and removes reference to them Parameters: Name Type Description request object response object next function Source: bridge.js distribute(filepath, metadata, object, callback) Takes the supplied file path and applies erasure codes, then attempts to distribute the shards across the network Parameters: Name Type Description filepath string Path to the file to distribute metadata object object ObjectPointer callback function Source: bridge.js Returns: Type EventEmitter downloadObject(request, response, next) Downloads the object from the network Parameters: Name Type Description request object response object next function Source: bridge.js error(error, request, response, next) Responds to requests with error code and message Parameters: Name Type Description error error request object response object next function Source: bridge.js getNodeStatus(request, response, next) Returns status information about the running node Parameters: Name Type Description request object response object next function Source: bridge.js getObjectInfo(request, response, next) Gets object information by unique ID Parameters: Name Type Description request object response object next function Source: bridge.js getObjectMagnet(request, response, next) Returns the magnet link for the given object Parameters: Name Type Description request object response object next function Source: bridge.js getPeerReputationScore(identity, callback) Calculates the percentile and relative usage allowance of the given identity Parameters: Name Type Description identity string 160 bit node identity key callback Directory~getPeerReputationScoreCallback Source: bridge.js listen(port, hostname, callback) Listens on the given port and hostname Parameters: Name Type Description port number hostname string callback function Source: bridge.js listObjects(request, response, next) Scans the object database and returns all index entries Parameters: Name Type Description request object response object next function Source: bridge.js notifyClients() Sends a state update payload to all connected clients via the websocket Source: bridge.js resolveObject(request, response, next) Accepts a body containing a magnet link, resolves the pointer and creates a local object pointer record, then returns it. Clients can follow with a GET /:id to download the object Parameters: Name Type Description request object response object next function Source: bridge.js retryUploadObject(request, response, next) Retries the object upload Parameters: Name Type Description request object response object next function Source: bridge.js scoreAndPublishAuditReports(callback) Takes all audit reports and reaps them while applying their results to local peer profile reputation score, then publishes the compressed payload to the bootstrap directory Parameters: Name Type Description callback function Source: bridge.js uploadObject(request, response, next) Queues the object for upload to the network Parameters: Name Type Description request object response object next function Source: bridge.js × Search results Close "},"Database.html":{"id":"Database.html","title":"Class: Database","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: Database Database Wraps a MongoDB connection and initializes models new Database(connectionUri) Parameters: Name Type Description connectionUri string Valid MongoDB URI string for connecting Source: database.js Classes AuditReport NetworkBlob ObjectPointer PeerProfile ShardContract × Search results Close "},"Database.AuditReport.html":{"id":"Database.AuditReport.html","title":"Class: AuditReport","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: AuditReport Database. AuditReport new AuditReport(properties) Describes the result of an audit as a report to directories Parameters: Name Type Description properties object Properties Name Type Description reporter string Identity key of the reporter provider string Identity key of the provider challenge string Challenge key given to provider expected string Expected challenge response actual string Actual challenge response Source: database.js Methods &lt;static&gt; methods.getSigningArray() Returns the array of keys needed to sign the report Source: database.js Returns: Type Array.&lt;string&gt; &lt;static&gt; methods.toCompressedAuthenticated(privateKey) Returns a serialized and cryptographically signed version of this report Parameters: Name Type Description privateKey buffer SECP256K1 private key Source: database.js Returns: Type Array.&lt;string&gt; &lt;static&gt; statics.verifyCompressedAuthenticated(compressed) Verifies the signature of a compressed and authenticated report Parameters: Name Type Description compressed Array.&lt;string&gt; The compressed report Source: database.js Returns: Type boolean × Search results Close "},"Database.NetworkBlob.html":{"id":"Database.NetworkBlob.html","title":"Class: NetworkBlob","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: NetworkBlob Database. NetworkBlob new NetworkBlob(properties) Some arbitrary blob of data stored in the DHT Parameters: Name Type Description properties object Properties Name Type Description key string 160 bit hexidecimal key (hash of value) value string Arbitrary value to store (base64) publisher string Identity key of the author of entry timestamp number Time the item was stored Source: database.js × Search results Close "},"Database.ObjectPointer.html":{"id":"Database.ObjectPointer.html","title":"Class: ObjectPointer","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: ObjectPointer Database. ObjectPointer new ObjectPointer(properties) Keeps references to the location of shards that compose an object Parameters: Name Type Description properties object Properties Name Type Argument Default Description name string &lt;optional&gt; untitled.blob Human readable object name encoding string &lt;optional&gt; File encoding type mimetype string &lt;optional&gt; application/octet MIME type hash string SHA-256 hash of the object size number Number of bytes in the object status string One of finished|queued|failed shards Array.&lt;object&gt; Properties Name Type Description size number Number of bytes in shard hash string RMD160 hash of shard service object Properties Name Type Description 0 string Identity key of provider 1 object Contact info of provider decayed boolean Flag if this shard is lost audits object Properties Name Type Description root string Merkle root for audit tree audit.challenges Array.&lt;string&gt; Audit challenges for shard audit.depth number Depth of audit merkle tree ecpub string SECP256K1 public key object is encrypted ecprv string SECP256K1 private key object is encrypted policies Array.&lt;string&gt; List of IMP-10 access policies Source: database.js Methods &lt;static&gt; methods.toEncryptedBlob() Returns a self encrypted blob version of the pointer Source: database.js Returns: Type object × Search results Close "},"Database.PeerProfile.html":{"id":"Database.PeerProfile.html","title":"Class: PeerProfile","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: PeerProfile Database. PeerProfile new PeerProfile(properties) Describes a known network peer Parameters: Name Type Description properties object Properties Name Type Description identity string Hexidecimal identity key contact object Properties Name Type Argument Default Description hostname string Onion service address port number Onion service virtual port protocol string &lt;optional&gt; https: Transport protocol xpub string HD public extended key index number Indentity key derivation index agent string &lt;optional&gt; User agent identifier capacity object Properties Name Type Description timestamp number Last capacity publication available number Bytes available at host allocated number Bytes allocated by host reputation object Properties Name Type Description score number Audit based reputation score timestamp number Last scoring time updated number Timestamp of last profile update Source: database.js Methods &lt;static&gt; methods.toString() Returns a human readable string URI for the peer Source: database.js Returns: Type string × Search results Close "},"Database.ShardContract.html":{"id":"Database.ShardContract.html","title":"Class: ShardContract","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: ShardContract Database. ShardContract new ShardContract(properties) Describes a contract between two peers for shard storage Parameters: Name Type Description properties object Properties Name Type Argument Default Description version number &lt;optional&gt; 2 Version of the contract type ownerParentKey string HD key for the shard owner ownerIndex number &lt;optional&gt; 0 HD index for the shard owner ownerIdentity string Identity key of the shard owner ownerSignature string Valid signature from owner providerParentKey string HD key for the shard owner providerIndex number &lt;optional&gt; 0 HD index for the shard owner providerIdentity string Identity key of the shard owner providerSignature string Valid signature from provider shardSize number Number of bytes in the shard shardHash string RMD160 SHA256 hash of shard auditLeaves Array.&lt;string&gt; Lower leaves of audit merkle tree auditInterval number Expect a challenge every N ms accessPolicies Array.&lt;string&gt; IMP-10 access policy strings fundingDestination string &lt;optional&gt; none Reserved for future Source: database.js Methods &lt;static&gt; methods.checkAccessPolicy(contact) Returns which, if any, methods are allowed by the access policy for the given contact Parameters: Name Type Description contact object Properties Name Type Description 0 string Identity key 1 object Contact information Source: database.js Returns: Type Array.&lt;string&gt; &lt;static&gt; methods.getSigningString() Returns the stringified version of the contract for signing Source: database.js Returns: Type string &lt;static&gt; methods.sign(actor, secret) Applies signature to contract as the given actor Parameters: Name Type Description actor string One of provider|owner secret buffer SECP256K1 private key Source: database.js Returns: Type string &lt;static&gt; methods.signExternal() Creates a signature of the contract given the SECP256K1 key Source: database.js Returns: Type string &lt;static&gt; methods.verify(actor) Verifies that the given actor signature is valid Parameters: Name Type Description actor string One of provider|owner Source: database.js Returns: Type boolean &lt;static&gt; methods.verifyExternal() Verifies the signature against a given public key Source: database.js Returns: Type boolean &lt;static&gt; statics.diff() Returns the property names that are different between two contracts Source: database.js Returns: Type Array.&lt;string&gt; × Search results Close "},"KadStorageAdapter.html":{"id":"KadStorageAdapter.html","title":"Class: KadStorageAdapter","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: KadStorageAdapter KadStorageAdapter Wraps the supplied model for a kad/levelup compatible interface new KadStorageAdapter(databaseModel) Parameters: Name Type Description databaseModel object Source: database.js Methods createReadStream() Returns a readable stream of all items Source: database.js Returns: Type ReadableStream del(key, callback) Delete item by key Parameters: Name Type Description key string 160 bit hex key callback function Source: database.js get(key [, options], callback) Get item by key Parameters: Name Type Argument Description key string 160 hex key options object &lt;optional&gt; Stubbed for levelup compatibility callback function Source: database.js put(key, value [, options], callback) Put item by key Parameters: Name Type Argument Description key string 160 bit hex key (hash of value) value object Arbitrary base64 string options object &lt;optional&gt; Stubbed for levelup compatibility callback function Source: database.js × Search results Close "},"module-orc_constants.html":{"id":"module-orc_constants.html","title":"Module: orc/constants","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Module: orc/constants Source: constants.js Members &lt;inner, constant&gt; AUDIT_BYTES :number Number of bytes for audit challenge Type: number Source: constants.js &lt;inner, constant&gt; AUDIT_INTERVAL :number Time interval for audit check Type: number Source: constants.js &lt;inner, constant&gt; CLEAN_INTERVAL :number Interval for reaping stale shards Type: number Source: constants.js &lt;inner, constant&gt; CONSIGN_THRESHOLD :number Threshold for consign time Type: number Source: constants.js &lt;inner, constant&gt; HD_KEY_DERIVATION_PATH :string Key derivation path for HD key Type: string Source: constants.js &lt;inner, constant&gt; MAX_DECAY :number Threshold for object decay for rebuilting Type: number Source: constants.js &lt;inner, constant&gt; MAX_NODE_INDEX :number Maximum node index Type: number Source: constants.js &lt;inner, constant&gt; NUM_CHALLENGES :number Total challenges to generate per object Type: number Source: constants.js &lt;inner, constant&gt; REAPER_GRACE :number Grace period beyond score interval Type: number Source: constants.js &lt;inner, constant&gt; SCORE_INTERVAL :number Time to score for reputation Type: number Source: constants.js &lt;inner, constant&gt; TOKEN_EXPIRE :number Reject data token after time Type: number Source: constants.js × Search results Close "},"module-orc_logger.html":{"id":"module-orc_logger.html","title":"Module: orc/logger","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Module: orc/logger Source: logger.js × Search results Close "},"module-orc_utils.html":{"id":"module-orc_utils.html","title":"Module: orc/utils","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Module: orc/utils Source: utils.js Methods &lt;static&gt; bufferAsReadableStream(buffer) Returns a readable stream version of the given buffer Parameters: Name Type Description buffer buffer Source: utils.js Returns: Type object &lt;static&gt; createCipher(publicKey, privateKey) Returns a cipher stream using aes256-cbc-sha256-hmac using a ECDH secret derived from the given public and private keys Parameters: Name Type Description publicKey buffer SECP256k1 public key bytes privateKey buffer SECP256k1 private key bytes Source: utils.js Returns: Type object &lt;static&gt; createComplexKeyFromSeed(seed64) Returns a HD key object using corrent key derivation path using the given seed Parameters: Name Type Description seed64 buffer 64 byte seed for generating key Source: utils.js Returns: Type HDKey &lt;static&gt; createDecipher(publicKey, privateKey) Returns a cipher stream using aes256-cbc-sha256-hmac using a ECDH secret derived from the given public and private keys Parameters: Name Type Description publicKey buffer SECP256k1 public key bytes privateKey buffer SECP256k1 private key bytes Source: utils.js Returns: Type object &lt;static&gt; createShardDownloader(farmer, hash, token [, agent]) Returns a request object for downloading a shard from a farmer Parameters: Name Type Argument Description farmer array Farmer contact object hash string The hash of the shard to upload token string The authorized transfer token agent Agent &lt;optional&gt; Source: utils.js Returns: Type https.ClientRequest &lt;static&gt; createShardUploader(farmer, hash, token [, agent]) Returns a request object for uploading a shard to a farmer Parameters: Name Type Argument Description farmer array Farmer contact object hash string The hash of the shard to upload token string The authorized transfer token agent Agent &lt;optional&gt; Source: utils.js Returns: Type https.ClientRequest &lt;static&gt; getCapacityFromFlags(flags) Returns a dictionary of capacity information from contact flags Parameters: Name Type Description flags array Source: utils.js Returns: Type object &lt;static&gt; getContactURL(contact) Returns a stringified URL from the supplied contact object Parameters: Name Type Description contact array Properties Name Type Description 0 string Node identity key 1 object Properties Name Type Description hostname string port string protocol string Source: utils.js Returns: Type string &lt;static&gt; getErasureParameters(n) Returns the appropriate shard size, number of shards, and number of parity shards for RS encoding/decoding provided the total number of bytes of the complete content Parameters: Name Type Description n number Number of bytes in data Source: utils.js Returns: Type object &lt;static&gt; getNextPowerOfTwo(number) Returns the next power of two number Parameters: Name Type Description number number Source: utils.js Returns: Type number &lt;static&gt; isCompatibleVersion(version) Returns whether or not the supplied semver tag is compatible Parameters: Name Type Description version string The semver tag from the contact Source: utils.js Returns: Type boolean &lt;static&gt; isHexaString(a) Determines if a value is hexadecimal string Parameters: Name Type Description a * The value to be tested Source: utils.js Returns: Type boolean &lt;static&gt; isValidContact(contact, loopback) Determines if the supplied contact is valid Parameters: Name Type Description contact array The contact information for a given peer loopback boolean Allows contacts that are localhost Source: utils.js Returns: Type boolean &lt;static&gt; isValidHDNodeKey(hdKey) Checks if the supplied HD key is valid (base58 encoded) and proper length Parameters: Name Type Description hdKey string The HD key in base 58 encoding Source: utils.js Returns: isValidHDKey Type boolean &lt;static&gt; isValidNodeIndex(hdIndex) Checks if the input is a non-hardened HD key index Parameters: Name Type Description hdIndex number The HD key index Source: utils.js Returns: isValidHDKeyIndex Type boolean &lt;static&gt; rmd160(input, encoding) Returns the RIPEMD-160 hash of the input Parameters: Name Type Description input string | buffer Data to hash encoding string The encoding type of the data Source: utils.js Returns: Type buffer &lt;static&gt; rmd160sha256(input, encoding) Returns the RIPEMD-160 SHA-256 hash of this input Parameters: Name Type Description input string | buffer Data to hash encoding string The encoding type of the data Source: utils.js Returns: Type buffer &lt;static&gt; sha256(input, encoding) Returns the SHA-256 hash of the input Parameters: Name Type Description input string | buffer Data to hash encoding string The encoding type of the data Source: utils.js Returns: Type buffer × Search results Close "},"module-orc_version.html":{"id":"module-orc_version.html","title":"Module: orc/version","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Module: orc/version Source: version.js Members &lt;inner, constant&gt; protocol :string The supported protocol version Type: string Source: version.js &lt;inner, constant&gt; software :string The current software version Type: string Source: version.js Methods &lt;static&gt; toString() Returns human readable string of versions Source: version.js Returns: Type string × Search results Close "},"Node.html":{"id":"Node.html","title":"Class: Node","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: Node Node Extends Kademlia with Orc protocol rules new Node(options) Parameters: Name Type Description options object Properties Name Type Argument Description privateExtendedKey string HD extended private key logger object &lt;optional&gt; Bunyan compatible logger transport Transport &lt;optional&gt; database Database shards Shards keyDerivationIndex number &lt;optional&gt; HD derivation index License: AGPL-3.0 Source: node.js Methods auditRemoteShards(peer, audits, callback) Sends the series of hash/challenge pairs to the remote node to request proof-of-storage Parameters: Name Type Description peer array Properties Name Type Description 0 string Identity key string 1 string | object Address data for contact audits Array.&lt;object&gt; Properties Name Type Description hash string Hash of the shard to prove challenge string Challenge string to prepend to shard callback Node~auditRemoteShardsCallback Source: node.js authorizeConsignment(peer, hashes, callback) Requests authorization tokens to push file shard(s) to another node Parameters: Name Type Description peer array Properties Name Type Description 0 string Identity key string 1 string | object Address data for contact hashes Array.&lt;string&gt; Hashes of the shards to push callback Node~authorizeConsignmentCallback Source: node.js authorizeRetrieval(peer, hashes, callback) Requests authorization tokens to pull file shard(s) from another node Parameters: Name Type Description peer array Properties Name Type Description 0 string Identity key string 1 string | object Address data for contact hashes Array.&lt;string&gt; Hashes of the shards to pull callback Node~authorizeRetrievalCallback Source: node.js claimProviderCapacity(peer, descriptor, callback) Claims capacity from a farming node, given a valid contract Parameters: Name Type Description peer array Properties Name Type Description 0 string Identity key string 1 string | object Address data for contact descriptor object Contract descriptor callback Node~claimProviderCapacityCallback Source: node.js createShardMirror(source, target, callback) Requests the source node to MIRROR a shard to the supplied destination Parameters: Name Type Description source array Properties Name Type Description 0 string Identity key string 1 string | object Address data for contact target object Properties Name Type Description destination array - Properties Name Type Description 0 string Identity key string 1 string | object Address data for contact hash string Hash of the shard to mirror token string Authorization token to PUSH shard callback Node~createShardMirrorCallback Source: node.js getBootstrapCandidates() Returns a list of bootstrap nodes from local profiles Source: node.js Returns: urls Type Array.&lt;string&gt; identifyService(url, callback) Sends a GET request to the URI and parses the result as a valid contact object with identity Parameters: Name Type Description url string The URL of the node callback Node~identifyServiceCallback Source: node.js listen() Adds the kademlia rule handlers before calling super#listen() Source: node.js reapExpiredShards() Scans the contract database for stale contracts to reap Source: node.js reportAuditResults(report, callback) Publishes the supplied audit reports to nearest neighbors Parameters: Name Type Description report Array.&lt;array&gt; callback Node~reportAuditResultsCallback Source: node.js requestContractRenewal(peer, contract, callback) Requests that the target peer update their local version of the given contract. Used to extend storage time or terminate storage. Peer will respond with an error or their updated, signed record of the renewal. Parameters: Name Type Description peer array Properties Name Type Description 0 string Identity key string 1 object Address data for contact contract object The completed shard descriptor contract callback Node~requestContractRenewalCallback Source: node.js updateFlags(soft) Performs any periodic updates to the contact flags we include in every message Parameters: Name Type Description soft boolean Don't do iterativeFindNode on update Source: node.js Type Definitions auditRemoteShardsCallback(error, proofs) Parameters: Name Type Description error object | null proofs Array.&lt;object&gt; Properties Name Type Description hash string Hash of the shard for corresponding proof proof string compact-merkle-proof Source: node.js authorizeConsignmentCallback(error, consignmentTokens) Parameters: Name Type Description error error | null consignmentTokens Array.&lt;string&gt; Source: node.js authorizeRetrievalCallback(error, retrievalTokens) Parameters: Name Type Description error error | null retrievalTokens Array.&lt;string&gt; Source: node.js claimProviderCapacityCallback(error, result) Parameters: Name Type Description error error | null result array Properties Name Type Description 0 object Completed contract result 1 string Consignment token Source: node.js createShardMirrorCallback(error) Parameters: Name Type Description error object | null Source: node.js identifyServiceCallback(error, contact) Parameters: Name Type Description error error | null contact array Source: node.js requestContractRenewalCallback(error, contract) Parameters: Name Type Description error error | null contract object See storage-contracts Source: node.js × Search results Close "},"Proof.html":{"id":"Proof.html","title":"Class: Proof","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: Proof Proof Provides interface for proving possession of a file for an AuditStream new Proof(merkleLeaves, hexChallenge) Parameters: Name Type Description merkleLeaves Array.&lt;string&gt; Bottom leaves of the audit merkle tree hexChallenge string | buffer The challenge data in hex to prepend to shard Source: proof.js Methods &lt;static&gt; verify(proof, root, depth) Verifies the proof given the merkle root and tree depth Parameters: Name Type Description proof * Compact proof result root string Merkle tree root from audit leaves depth number Depth of the merkle tree Source: proof.js Returns: Type Array.&lt;string&gt; getProofResult() Returns the generated proof structure Source: proof.js Returns: Type array × Search results Close "},"Rules.html":{"id":"Rules.html","title":"Class: Rules","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: Rules Rules Represents Orc protocol handlers new Rules(node) Constructs a Orc rules instance in the context of a Orc node Parameters: Name Type Description node Node Source: rules.js Methods audit(request, response) Upon receipt of a AUDIT message, the node must look up the contract that is associated with each hash-challenge pair in the payload, prepend the challenge to the shard data, and caclulate the resulting hash, formatted as a compact proof. See compact-proofs. Parameters: Name Type Description request object response object Source: rules.js claim(request, response) Upon receipt of an `CLAIM` message, nodes must validate the descriptor, then ensure that there is enough available space for the shard. If both checks succeed, then the descriptor is signed and returned along with a consignment token so the initiating renter can immediately upload the data. These messages are generally sent based on information collected when subscribed to farmer capacity publications. Parameters: Name Type Description request object response object Source: rules.js consign(request, response) Upon receipt of a CONSIGN message, the node must verify that it has a valid storage allocation and contract for the supplied hash and identity of the originator. If so, it must generate an authorization token which will be checked by the shard server before accepting the transfer of the associated shard. Parameters: Name Type Description request object response object Source: rules.js renew(request, response) Upon receipt of a RENEW message, the recipient farmer must extend or terminate it's contract based on the new terms supplied by the renter. If the renewal descriptor is valid and complete, the farmer must store the updated version after signing and respond back to the originator with the version containing the updated signature. Parameters: Name Type Description request object response object Source: rules.js retrieve(request, response) Upon receipt of a RETRIEVE message, the node must verify that it is in possession of the shard on behalf of the identity of the originator. If so, it must generate an authorization token which will be checked by the shard server before accepting the transfer of the associated shard. Parameters: Name Type Description request object response object Source: rules.js validate(request, response) Validates all incoming RPC messages Parameters: Name Type Description request object response object Source: rules.js × Search results Close "},"Server.html":{"id":"Server.html","title":"Class: Server","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: Server Server Creates a shard server for sending and receiving consigned file shards new Server(options) Parameters: Name Type Description options object Properties Name Type Argument Default Description identity string Node identity key database Database shards Shards tokenTtl number &lt;optional&gt; 1800000 Expire unused token Source: server.js Methods accept(token, filehash, contact) Begin accepting data for the given file hash and token Parameters: Name Type Description token string The authorization token created for transfer filehash string The shard hash to allow for the token contact array Contact that negotiated the token Source: server.js authorize(token, hash) Validates the given token Parameters: Name Type Description token string hash string Source: server.js Returns: Type object download(req, res) Pumps the data through to the client Parameters: Name Type Description req http.IncomingMessage res http.ServerResponse Source: server.js reject(token) Stop accepting data for the given token Parameters: Name Type Description token string The authorization token created for transfer Source: server.js upload(req, req) Receives the data stream and writes it to storage Parameters: Name Type Description req http.IncomingMessage req http.ServerResponse Source: server.js Events error Triggered when a error occurs Parameters: Name Type Description error error Source: server.js shardDownloaded Triggered when a shard has finished downloading from this instance Parameters: Name Type Description hash string The hash associated with the download Source: server.js shardUploaded Triggered when a shard has finished uploading to this instance Parameters: Name Type Description hash string The hash associated with the upload Source: server.js × Search results Close "},"Shards.html":{"id":"Shards.html","title":"Class: Shards","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: Shards Shards Convenience wrapper for storing shards scoped to a directory new Shards(directory) Parameters: Name Type Description directory string Directory path to shard storage Source: shards.js Methods createReadStream(key, callback) Wraps read stream with error handling/callback Parameters: Name Type Description key string The file key or hash callback Shards~createReadStreamCallback Source: shards.js createWriteStream(key, callback) Wraps write stream with error handling/callback Parameters: Name Type Description key string The file key or hash callback Shards~createWriteStreamCallback Source: shards.js exists(key, callback) Check if the shard exists Parameters: Name Type Description key string callback Shards~existsCallback Source: shards.js size(callback) Get used space and remaining allocation Parameters: Name Type Description callback Shards~sizeCallback Source: shards.js unlink(key, callback) Unlink the shard from the file system Parameters: Name Type Description key string callback Shards~unlinkCallback Source: shards.js Type Definitions createReadStreamCallback(error, stream) Parameters: Name Type Description error error | null stream object Source: shards.js createWriteStreamCallback(error, stream) Parameters: Name Type Description error error | null stream object Source: shards.js existsCallback(error, exists) Parameters: Name Type Description error error | null exists boolean Source: shards.js unlinkCallback(error) Parameters: Name Type Description error error | null Source: shards.js × Search results Close "},"Transport.html":{"id":"Transport.html","title":"Class: Transport","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Class: Transport Transport Represents the ORC-specific HTTP transport new Transport() Contructs a Orc transport adapter Source: transport.js Events download Emitted when a download request is received Parameters: Name Type Description request object response object Source: transport.js upload Emitted when a upload request is received Parameters: Name Type Description request object response object Source: transport.js × Search results Close "},"tutorial-api.html":{"id":"tutorial-api.html","title":"Tutorial: Using the REST API","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Using the REST API This guide will show you how to configure your node to expose a simple REST API that applications can use to upload, download, delete, and list objects you have stored in the network as well as get status information. Make sure you've read over the Configuration Guide and understand the the security implications for various settings related the the local bridge. For the purposes of brevity for this guide, we are going to assume the following configuration scheme and will use curl for the examples: BridgeEnabled = 1 BridgeHostname = 127.0.0.1 BridgePort = 4445 BridgeAuthenticationEnabled = 0Status UpdatesYou can get detailed status updates on progress of a transfer using the event controller. Connect to the local bridge using a WebSocket. If you have authentication enabled, be sure to send the appropriate Authorization: Basic &lt;base64(user:pass)&gt; header when creating the request. You will receive messages indicating the status of transfers in the form of JSON-RPC notification payloads including [reference, message, data], where the method can be: CONNECT_INFO LOG_RAW TRANSFER_DOWN_INFO TRANSFER_DOWN_FAIL TRANSFER_DOWN_PASS TRANSFER_UP_INFO TRANSFER_UP_PASS TRANSFER_UP_FAIL The reference parameter will be either null if CONNECT_INFO or the hash of the object the status message is about if TRANSFER_*. This can be used to get the progress data about a pending upload or download. GET /Fetches general status information about the running node. $ curl http://127.0.0.1:4445 | jq { &quot;identity&quot;: &quot;96fecf94aadc37b73955d991a4d4b27586a1090e&quot;, &quot;contact&quot;: { &quot;hostname&quot;: &quot;wwv6224ikwi72alxt5dt6o3flawgcqk6aywerqk6dlcl4nsrdguihvyd.onion&quot;, &quot;protocol&quot;: &quot;http:&quot;, &quot;port&quot;: &quot;80&quot;, &quot;xpub&quot;: &quot;xpub6AfC24JPejm52SjzZBc873mFkpugSTaaDd7sRw294h9ZSkoFeWwLg9WoqYdrVsPDHhrrc9doE257ZVSDEeguJU1jS97h1agZAsot3bLMqeV&quot;, &quot;index&quot;: 0, &quot;agent&quot;: &quot;4.0.0&quot;, &quot;flags&quot;: [ [ &quot;ALLOCATED&quot;, 0 ], [ &quot;AVAILABLE&quot;, 0 ] ] }, &quot;peers&quot;: [ [ &quot;02e1829bc163f87f7e0493fbdf716445d4be9501&quot;, { &quot;hostname&quot;: &quot;l466qntstik7falkkzxttgrtlu4u7g6yaxmyvjs2qamlzymsdsiqxdqd.onion&quot;, &quot;protocol&quot;: &quot;http:&quot;, &quot;port&quot;: &quot;80&quot;, &quot;xpub&quot;: &quot;xpub6BQnZfspXVdRB8y9DrWV1oS9XxAMKsyZCazYxfaxhNbVaM9vtbtEmQTeCBkhizHX8gutN3bvJBzoucZ2SsANaeikXJdiLQNJj7W7Wf1uhje&quot;, &quot;index&quot;: 0, &quot;agent&quot;: &quot;4.0.0&quot;, &quot;flags&quot;: [ [ &quot;ALLOCATED&quot;, 1073741824 ], [ &quot;AVAILABLE&quot;, 1073737728 ] ] } ], [ &quot;75052f451c7250a7b82cb31009bdcf776daed45d&quot;, { &quot;hostname&quot;: &quot;dah2cohegwnmbipbdd5rkbdc2m5tfabvtuukqjvlcvoul2bxwtb6ggid.onion&quot;, &quot;protocol&quot;: &quot;http:&quot;, &quot;port&quot;: &quot;80&quot;, &quot;xpub&quot;: &quot;xpub6BUktL3tg7yjsJE6hNiXXEARN7TkCp6Zq6D6K9Y7uMBQFc2zBjFgsZtDynG3557K4w2weUbNgHue52x1tUYXMkzh4NRhmxnqdvCrkexH9UE&quot;, &quot;index&quot;: 0, &quot;agent&quot;: &quot;4.0.0&quot;, &quot;flags&quot;: [ [ &quot;ALLOCATED&quot;, 1073741824 ], [ &quot;AVAILABLE&quot;, 1073737728 ] ] } ], [ &quot;6605c168587c5ca7a85203e1609054b1e981dba1&quot;, { &quot;hostname&quot;: &quot;zibvvc4jh3j2czhpwklpa3dphvltad4vsb3cziym7z2smep5sc2bfdad.onion&quot;, &quot;protocol&quot;: &quot;http:&quot;, &quot;port&quot;: &quot;80&quot;, &quot;xpub&quot;: &quot;xpub6AjnKeVDsSPM9v4KMyRLrsyWqH2L2sJywBP3BM21EBdTMEd2nccW6bxTrpiaoBko5yYHEhAReTCL6pUk1jheAfeHuHy58sJ9L7C1kyUW5cd&quot;, &quot;index&quot;: 0, &quot;agent&quot;: &quot;4.0.0&quot;, &quot;flags&quot;: [ [ &quot;ALLOCATED&quot;, 1073741824 ], [ &quot;AVAILABLE&quot;, 1073737728 ] ] } ] ], &quot;providing&quot;: { &quot;allocated&quot;: 0, &quot;available&quot;: 0 }, &quot;versions&quot;: { &quot;protocol&quot;: &quot;4.0.0&quot;, &quot;software&quot;: &quot;10.0.0&quot; } }GET /providersFetches a JSON array of all identities and their associated profiles for which the node has interacted with in the past 24 hours. $ curl http://127.0.0.1:4445/providers | jq [ { &quot;identity&quot;: &quot;87e37cf78128e77cb489deb0f5e9d71adad9fc8d&quot;, &quot;updated&quot;: &quot;2017-12-02T14:47:41.311Z&quot;, &quot;reputation&quot;: { &quot;timestamp&quot;: &quot;2017-12-02T14:48:17.378Z&quot;, &quot;score&quot;: 0 }, &quot;capacity&quot;: { &quot;available&quot;: 1073737728, &quot;allocated&quot;: 1073741824 }, &quot;contact&quot;: { &quot;xpub&quot;: &quot;xpub6A5t8evFXdEUrjojnKHJ8Z6ouc9Zuoj9MTW9MpvmzaLKLCF9zAtwQVu8AVDTy32BxeJWYQbw2Nc2TM1GhNzG3aYctfNZoeMNZBcxm19Emny&quot;, &quot;port&quot;: 80, &quot;hostname&quot;: &quot;efoe6we3k7qifabypkwrnms2wjeqm2q5x3bqomfcpp4fliazc6h2hfid.onion&quot;, &quot;agent&quot;: &quot;4.0.0&quot;, &quot;index&quot;: 0, &quot;protocol&quot;: &quot;http:&quot; } } ]GET /providers/{identity}Given a known identity key, fetch the specific profile associated. $ curl http://127.0.0.1:4445/87e37cf78128e77cb489deb0f5e9d71adad9fc8d | jq { &quot;identity&quot;: &quot;87e37cf78128e77cb489deb0f5e9d71adad9fc8d&quot;, &quot;updated&quot;: &quot;2017-12-02T14:47:41.311Z&quot;, &quot;reputation&quot;: { &quot;timestamp&quot;: &quot;2017-12-02T14:48:17.378Z&quot;, &quot;score&quot;: 0 }, &quot;capacity&quot;: { &quot;available&quot;: 1073737728, &quot;allocated&quot;: 1073741824 }, &quot;contact&quot;: { &quot;xpub&quot;: &quot;xpub6A5t8evFXdEUrjojnKHJ8Z6ouc9Zuoj9MTW9MpvmzaLKLCF9zAtwQVu8AVDTy32BxeJWYQbw2Nc2TM1GhNzG3aYctfNZoeMNZBcxm19Emny&quot;, &quot;port&quot;: 80, &quot;hostname&quot;: &quot;efoe6we3k7qifabypkwrnms2wjeqm2q5x3bqomfcpp4fliazc6h2hfid.onion&quot;, &quot;agent&quot;: &quot;4.0.0&quot;, &quot;index&quot;: 0, &quot;protocol&quot;: &quot;http:&quot; } }GET /providers/{identity}/scoreGiven a known identity key, rank their reputation score into a percentile and report their estimated utilization allowance. $ curl http://127.0.0.1:4445/87e37cf78128e77cb489deb0f5e9d71adad9fc8d/score | jq { &quot;identity&quot;: &quot;87e37cf78128e77cb489deb0f5e9d71adad9fc8d&quot;, &quot;percentile&quot;: 0, &quot;allowance&quot;: null, &quot;score&quot;: 0, &quot;capacity&quot;: { &quot;allocated&quot;: 3221225472, &quot;available&quot;: 3221213184 } }GET /objectsRetreive a JSON list of your objects stored in the network and managed by this node. Each item returned in the list contains metadata regarding the type, size, name, hash, location of shards, and more. $ curl http://127.0.0.1:4445/objects | jq [ { &quot;encoding&quot;: &quot;7bit&quot;, &quot;size&quot;: 43472, &quot;ecpub&quot;: &quot;02dc3937fd97fc26a54ad976c4cda37eb513d9a86debca18dd6f2e83717c9227d3&quot;, &quot;hash&quot;: &quot;24081ee6fd4a5395a44597e36c5314b1308a197137db45e08d6d86aa070fbe84&quot;, &quot;status&quot;: &quot;finished&quot;, &quot;policies&quot;: [ &quot;::RETRIEVE&quot; ], &quot;shards&quot;: [ { &quot;size&quot;: 21744, &quot;hash&quot;: &quot;e1eede74c9512f1994b18eac6465a0b471201548&quot;, &quot;service&quot;: [ &quot;ccfbab389c9c547badb708021c0eaad4d9ec87ed&quot;, { &quot;agent&quot;: &quot;orc-8.1.1-beta5/linux&quot;, &quot;index&quot;: 2, &quot;xpub&quot;: &quot;xpub6BRiU17o5vnTq8sGX2DgjBoU1ozBZnBDiW4avCwoFUzcYtrHMKxs8BjdS3qt6AAv42KDE2B4D2q3Fj3cYuzuCFoDijnQKJYvoMLJV2rEGVL&quot;, &quot;port&quot;: 443, &quot;protocol&quot;: &quot;https:&quot;, &quot;hostname&quot;: &quot;orcwfkilxjxo63mr.onion&quot; } ] }, { &quot;size&quot;: 21744, &quot;hash&quot;: &quot;0a2f5a2a47ffe851403bfb4dc56be9b09392d182&quot;, &quot;service&quot;: [ &quot;681069cc9dc643999be1031a8740d2a341939262&quot;, { &quot;agent&quot;: &quot;orc-8.1.1-beta6/linux&quot;, &quot;index&quot;: 0, &quot;xpub&quot;: &quot;xpub6ARoW5DJo4xBbob8Gr3HReVU3qqJQpBRqBR2SDJkaYq5eJGL17yhGijXzkmobJe3f5nPHyZrohWR5txhCUjiXvhfCR3v2vmc7MuAYCcrTbt&quot;, &quot;port&quot;: 443, &quot;protocol&quot;: &quot;https:&quot;, &quot;hostname&quot;: &quot;puiq7u4bw6lroev5.onion&quot; } ] }, { &quot;size&quot;: 21744, &quot;hash&quot;: &quot;4c38ad2a132b8d683abcc73f2eddf9d2700ad5d7&quot;, &quot;service&quot;: [ &quot;1723b631252fc5f50ba43a8cfd2f38cba0daf44c&quot;, { &quot;agent&quot;: &quot;orc-8.1.1-beta1/linux&quot;, &quot;index&quot;: 0, &quot;xpub&quot;: &quot;xpub6AxEbAJY7bV33paGh9wbGgDh7q6T67LQKBEbo93vxez4zPF4sQQnNHK55suXWk4ViZYsjy1jwdUtuuWosUWAyEQMeqXmJKhbbuZnAcGLQRF&quot;, &quot;port&quot;: 443, &quot;protocol&quot;: &quot;https:&quot;, &quot;hostname&quot;: &quot;wifniq3h3gqm2b2w.onion&quot; } ] } ], &quot;mimetype&quot;: &quot;image/png&quot;, &quot;name&quot;: &quot;avatar.png&quot;, &quot;id&quot;: &quot;59d2627ebb28977b0e6ab841&quot; } ]GET /objects/{id}/infoRetrieve the metadata for a specific object by it's unique ID. $ curl http://127.0.0.1:4445/objects/59d2627ebb28977b0e6ab841/info | jq { &quot;encoding&quot;: &quot;7bit&quot;, &quot;size&quot;: 43472, &quot;ecpub&quot;: &quot;02dc3937fd97fc26a54ad976c4cda37eb513d9a86debca18dd6f2e83717c9227d3&quot;, &quot;hash&quot;: &quot;24081ee6fd4a5395a44597e36c5314b1308a197137db45e08d6d86aa070fbe84&quot;, &quot;status&quot;: &quot;finished&quot;, &quot;policies&quot;: [ &quot;::RETRIEVE&quot; ], &quot;shards&quot;: [ { &quot;size&quot;: 21744, &quot;hash&quot;: &quot;e1eede74c9512f1994b18eac6465a0b471201548&quot;, &quot;service&quot;: [ &quot;ccfbab389c9c547badb708021c0eaad4d9ec87ed&quot;, { &quot;agent&quot;: &quot;orc-8.1.1-beta5/linux&quot;, &quot;index&quot;: 2, &quot;xpub&quot;: &quot;xpub6BRiU17o5vnTq8sGX2DgjBoU1ozBZnBDiW4avCwoFUzcYtrHMKxs8BjdS3qt6AAv42KDE2B4D2q3Fj3cYuzuCFoDijnQKJYvoMLJV2rEGVL&quot;, &quot;port&quot;: 443, &quot;protocol&quot;: &quot;https:&quot;, &quot;hostname&quot;: &quot;orcwfkilxjxo63mr.onion&quot; } ] }, { &quot;size&quot;: 21744, &quot;hash&quot;: &quot;0a2f5a2a47ffe851403bfb4dc56be9b09392d182&quot;, &quot;service&quot;: [ &quot;681069cc9dc643999be1031a8740d2a341939262&quot;, { &quot;agent&quot;: &quot;orc-8.1.1-beta6/linux&quot;, &quot;index&quot;: 0, &quot;xpub&quot;: &quot;xpub6ARoW5DJo4xBbob8Gr3HReVU3qqJQpBRqBR2SDJkaYq5eJGL17yhGijXzkmobJe3f5nPHyZrohWR5txhCUjiXvhfCR3v2vmc7MuAYCcrTbt&quot;, &quot;port&quot;: 443, &quot;protocol&quot;: &quot;https:&quot;, &quot;hostname&quot;: &quot;puiq7u4bw6lroev5.onion&quot; } ] }, { &quot;size&quot;: 21744, &quot;hash&quot;: &quot;4c38ad2a132b8d683abcc73f2eddf9d2700ad5d7&quot;, &quot;service&quot;: [ &quot;1723b631252fc5f50ba43a8cfd2f38cba0daf44c&quot;, { &quot;agent&quot;: &quot;orc-8.1.1-beta1/linux&quot;, &quot;index&quot;: 0, &quot;xpub&quot;: &quot;xpub6AxEbAJY7bV33paGh9wbGgDh7q6T67LQKBEbo93vxez4zPF4sQQnNHK55suXWk4ViZYsjy1jwdUtuuWosUWAyEQMeqXmJKhbbuZnAcGLQRF&quot;, &quot;port&quot;: 443, &quot;protocol&quot;: &quot;https:&quot;, &quot;hostname&quot;: &quot;wifniq3h3gqm2b2w.onion&quot; } ] } ], &quot;mimetype&quot;: &quot;image/png&quot;, &quot;name&quot;: &quot;avatar.png&quot;, &quot;id&quot;: &quot;59d2627ebb28977b0e6ab841&quot; }POST /objectsYou can upload a file to the network my sending a multipart/form-upload request to POST /. This works the same as if using a &lt;input type=&quot;file&quot;/&gt; on a web page. You can also add policy fields to specify access policies as defined in IMP-0010. $ curl -F &quot;file=@avatar.png;type=image/png;&quot; -F &quot;policy=::RETRIEVE&quot; http://127.0.0.1:4445/objects | jqOnce the object is completely distributed, the metadata will be returned. You can check on the status of an object while the request is pending by listing the objects using GET /. Statuses may be finished, queued, or failed. PUT /objects/{id}In the event that an upload fails due to network issues, it will end up in a &quot;queued&quot; state, which allows for it to have a retry triggered by sending this request. The result of this request is identical to uploading an object and is functionally equivalent, except instead of first accepting the file as part of the request, it will use the already encrypted copy stored locally. $ curl -X PUT http://127.0.0.1:4445/objects/59d2627ebb28977b0e6ab841 | jqGET /objects/{id}You can download a file from the network knowing only the object's ID in the local bridge service. The appropriate headers for content type are sent to enable browsers and other applications to display the downloaded object. $ curl http://127.0.0.1:4445/objects/59d2627ebb28977b0e6ab841 &gt;&gt; avatar.png Note that decryption is performed by the local bridge service, so it is very important to configure your bridge to use authentication if exposing as an onion service and SSL if exposing over the clearnet. GET /objects/{id}/magnetIf you supplied an appropriate access policy field on upload, you can share a magnet link with others to fetch the object pointer. $ curl http://127.0.0.1:4445/objects/59d2627ebb28977b0e6ab841/magnet | jq { &quot;href&quot;: &quot;magnet:?xt=urn:orc:a3cd254243fc02579384d75cba2588a6c9e850d1&amp;xs=43472&amp;dn=avatar.png&amp;x.ecprv=2daade3b5a4af3641e22cb0317cadf3115bc4b800e0eceaa1a4568c53e60911b&amp;x.pword=17300e194a57251388e98b104411b2004223fe7a&quot; }This will return a magnet link that contains the hash of the encrypted pointer so it can be looked up in the DHT, the name and size of the object referenced for interfaces to use, the key used to encrypt the pointer, and the key used to encrypt the object. Note that this link can be used by anyone to download the pointer, which allows anyone who is included in the object's access policy to download and decrypt the object itself. PUT /objectsTo fetch an object pointer shared by someone else, you can send the magnet link and get back an object pointer with an ID you can use in the download example. curl -X PUT --data &quot;magnet:?xt=...&quot; http://127.0.0.1:4445/objects Protip! Pipe the output of the example above through jq -r .href | xclip -selection clipboard to copy the magnet link directly to your clipboard. ;) DELETE /objects/{id}You can destroy an object, nullifying associated contracts by sending a DELETE /{id} request. $ curl -X &quot;DELETE&quot; http://127.0.0.1:4445/objects/59d2627ebb28977b0e6ab841 × Search results Close "},"tutorial-config.html":{"id":"tutorial-config.html","title":"Tutorial: Configuration Guide","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Configuration Guide This guide will show you how to get started with running orcd! An ORC node requires a configuration file to get up and running. The path to this file is given to orcd when starting a node. orcd --config path/to/orc.configIf a configuration file is not supplied, a minimal default configuration is automatically created and used, which will generate a private extended key, storage for shards, contracts, and network information. All of this data will be created and stored in $HOME/.config/orcd, yielding a directory structure like this: +- ~/.config/orcd + - x_private_key (Root/Parent HD identity key) + - config (INI configuration file) + - orcd.log (Daemon log file, rotated periodically) + - /provider_vault (Directory containing encrypted shards named by hash) + - /node_data (MongoDB data directory) + - /node_hs (Tor + hidden service data directory)The locations of all of these files is defined in your configuration file. Below is an complete outline of each valid configuration property name, it's behavior, and default value(s). Valid configuration files may be in either INI or JSON format. DaemonPidFilePathDefault: $HOME/.config/orcd/orcd.pidThe location to write the PID file for the daemon. PrivateExtendedKeyPathDefault: $HOME/.config/orcd/x_private_keyPath to private extended key file to use for master identity. ChildDerivationIndexDefault: 0The index for deriving this child node's identity. This allows you to run multiple nodes with the same private extended key. If your private extended key was converted from an old non-hierarchically-deterministic private key, you must set the value to -1. MongoDBDataDirectoryDefault: $HOME/.config/orcd/node_dataSets the directory to store MongoDB database files. MongoDBPortDefault: 37017Sets the TCP port to binding the mongod process. ShardStorageDataDirectoryDefault: $HOME/.config/orcd/provider_vaultSet the base directory (parent) for where shards will be placed. This directory stores other nodes' data shards, so be sure you set this to where you intend to provide capacity. ShardReaperIntervalDefault: 24HRHow often we should scan contract database to reap expired shards it is storing. Accepts human-readable strings like 3DAYS or 72HOURS ShardStorageMaxAllocationDefault: 0GBDefine the maximum size you wish to allocate for farming shards. This can be increased later, but decreasing it will not delete existing data. ShardReaperInvalidationBlocksDefault: 240The number of blocks added to chain without payment since a contract was stored to determine whether or not the data should be reaped. ShardCapacityUpdateIntervalDefault: 30MThe frequency interval we update our flags to reflect our available capacity. NodeOnionServiceDataDirectoryDefault: $HOME/.config/orcd/node_hsThe path to the directory to instruct Tor to use for storing hidden service keys and other information. NodeVirtualPortDefault: 80Sets the virtual port number for your node's RPC onion service. NodeListenPortDefault: 9088Sets the local port to bind the node's RPC service. BandwidthAccountingEnabledDefault: 0Enables bandwidth metering and hibernation mode. When the property BandwidthAccountingEnabled is 1, we will enter low-bandwidth mode if the we exceed BandwidthAccountingMax within the period defined by BandwidthAccountingReset until the interval is finished. BandwidthAccountingMaxDefault: 5GBSets the maximum number of bandwidth to use per accounting interval for data transfer. Low-bandwidth RPC messages will still be allowed. BandwidthAccountingResetDefault: 24HRResets the bandwidth accounting on an interval defined by this property. VerboseLoggingEnabledDefault: 1More detailed logging of messages sent and received. Useful for debugging. LogFilePathDefault: $HEAD/.config/orcd.logPath to write the daemon's log file. Log file will rotate either every 24 hours or when it exceeds 10MB, whichever happens first. LogFileMaxBackCopiesDefault: 3Maximum number of rotated log files to keep. NetworkBootstrapNodes[]Default: http://z2ybz7kjxjtfiwcervfh376swy4je3ye4yne2atoi727634qzjonk7id.onion:80Add a map of network bootstrap nodes to this section to use for discovering other peers. Default configuration should come with a list of known and trusted contacts. BridgeHostnameDefault: 127.0.0.1Sets the hostname or IP address to which the bridge service should be bound. It is important to set this value to a loopback address if authentication is disabled to prevent others from accessing your objects. BridgePortDefault: 9089Set the TCP port to which the bridge service's HTTP API should be bound. BridgeAuthenticationEnabledDefault: 1Force requests to the bridge service API to supply credentials using HTTP Basic Authentication. BridgeAuthenticationUserDefault: orcUser name to require using HTTP Basic Authentication. BridgeAuthenticationPasswordDefault: &lt;random&gt;Password to require using HTTP Basic Authentication. BridgeTempStagingBaseDirDefault: $HOME/.config/orcd/tmpSets the path on the filesystem to a directory for storing temporary data for queued uploads. ProviderCapacityPoolTimeoutDefault: 24HRIf we haven't received a relayed capacity announcement from a peer within this defined timeframe, remove them from the provider pool until we receive an announcement again. Prevents attempting to use providers that are unlikely to be available. ProviderFailureBlacklistTimeoutDefault: 6HRIf we have tried to store a shard with a peer and a failure occurred on the provider's end, temporarily remove them from the provider pool for this defined amount of time. TorPassthroughLoggingEnabledDefault: 0Redirects the Tor process log output through ORC's logger for the purpose of debugging. TorLoggingVerbosityDefault: noticeDefines the verbosity level of the Tor process logging. Valid options are: debug, info, notice. ProviderBondDepositAmountDefault: 0Minimum tokens bonded in order to establish baseline trust with a storage provider. × Search results Close "},"tutorial-install.html":{"id":"tutorial-install.html","title":"Tutorial: Manual Installation","body":" ORC Modules orc/constantsorc/loggerorc/utilsorc/version Classes AuditBridgeDatabaseDatabase.AuditReportDatabase.NetworkBlobDatabase.ObjectPointerDatabase.PeerProfileDatabase.ShardContractKadStorageAdapterNodeProofRulesServerShardsTransport Events Server#event:errorServer#event:shardDownloadedServer#event:shardUploadedTransport#event:downloadTransport#event:upload Tutorials Using the REST APIConfiguration GuideManual Installation Manual Installation Make sure you have the following prerequisites installed: Tor Git Node.js LTS + NPM (6.10.x) Python 2.7 GCC/G++/Make Node.js + NPMGNU+Linux &amp; Mac OSXwget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.0/install.sh | bashClose your shell and open an new one. Now that you can call the nvm program, install Node.js (which comes with NPM): nvm install --ltsBuild DependenciesGNU+LinuxDebian / Ubuntu / Mint / Trisquel / and Friends apt install git python build-essentialRed Hat / Fedora / CentOS yum groupinstall 'Development Tools'You might also find yourself lacking a C++11 compiler - see this. Mac OSXxcode-select --installWindowsRun as administrator in PowerShell or cmd: npm install -g windows-build-toolsDaemon + Utilities CLIThis package exposes 3 programs: orc, orcd, and orctool. To install these, use the --global flag. GRANAX_USE_TOR_ALPHA=1 npm install -g @orcproject/orcCore LibraryThis package exposes a module providing a complete implementation of the protocol. To use it in your project, from your project's root directory, install as a dependency. GRANAX_USE_TOR_ALPHA=1 npm install @orcproject/orc --saveThen you can require the library with: const orc = require('@orcproject/orc'); × Search results Close "}}
    </script>

    <script type="text/javascript">
        $(document).ready(function() {
            Searcher.init();
        });

        $(window).on("message", function(msg) {
            var msgData = msg.originalEvent.data;

            if (msgData.msgid != "docstrap.quicksearch.start") {
                return;
            }

            var results = Searcher.search(msgData.searchTerms);

            window.parent.postMessage({"results": results, "msgid": "docstrap.quicksearch.done"}, "*");
        });
    </script>
</body>
</html>
